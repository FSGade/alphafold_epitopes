{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de590a4d",
   "metadata": {},
   "source": [
    "# PREDICTION OF EPITOPES USING ALPHAFOLD2 STRUCTURES AND GRAPH NEURAL NETWORKS\n",
    ">#### Magnus H. HÃ¸ie (s216559), Frederik S. Gade (s184260), Ida Meitil (s153020)\n",
    "> Epitopes are surface-exposed regions of a pathogenic molecule or antigen, which are targeted\n",
    "by the adaptive immune system by e.g. B-cell receptors. Binding is largely determined by the\n",
    "surface features of the target molecule. AlphaFold2 is a deep-learning protein folding model\n",
    "achieving near experimental quality prediction for many proteins. Furthermore, graph-based\n",
    "neural networks such as ProteinSolver allow structural representation of proteins suitable for\n",
    "tasks such as epitope prediction. We investigate improved epitope prediction using Alphafold2\n",
    "modelled structures over sequence-only models.\n",
    ">\n",
    ">*02456 DEEP LEARNING, DTU COMPUTE, FALL 2021*\n",
    "\n",
    "\n",
    "Running this notebook requires specific versions of PyTorch and associated packages to be compatible with ProteinSolver. The following commands should suffice: \n",
    "\n",
    "```\n",
    "conda env create -f PS_gpu.yaml\n",
    "conda activate PS_gpu\n",
    "conda install nb_conda \n",
    "```\n",
    "\n",
    "*Note that installing* `nb_conda` *makes it possible to use the conda environment in jupyter*\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69c69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn, Tensor, sigmoid, tanh, relu, softmax\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import kmbio\n",
    "from kmbio import PDB\n",
    "from Bio import SeqIO\n",
    "import torch_geometric\n",
    "\n",
    "import ProteinSolver as proteinsolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162f0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"data/cleaned_pdbs/\"\n",
    "STATE_FILE = \"ProteinSolver/e53-s1952148-d93703104.state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61f0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AF2 structures for FFNN and RNN\n",
      "The device in use is cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "EARLY_STOPPING = True\n",
    "\n",
    "SOLVED = False\n",
    "print(\"Using {} structures for FFNN, RNN and Discotope\".format(\"solved\" if SOLVED else \"AF2\"))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"The device in use is\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4809d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SOLVED:\n",
    "    SEQ_KEY_NAME = \"seq_pdb\"\n",
    "    embedding_type = \"data/solved_embeddings/\"\n",
    "else:\n",
    "    SEQ_KEY_NAME = \"seq\"\n",
    "    embedding_type = \"data/af2_embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d262777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpitopeDataset(data.Dataset):\n",
    "    def __init__(self,embeddings,labels,mask,batch=4):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.embeddings).shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.embeddings[idx] , self.labels[idx], self.mask[idx]\n",
    "\n",
    "def create_sequential_datasets(list_of_dicts):\n",
    "    n_seqs = len(list_of_dicts)\n",
    "    seq_max_length = max([len(embed_dict[SEQ_KEY_NAME]) for embed_dict in list_of_dicts])\n",
    "    embedding_dim = 128\n",
    "\n",
    "    with open(\"data/postapr2018_antigens.test.txt\", \"r\") as infile:\n",
    "        test_names = set([l.strip() for l in infile.readlines()])\n",
    "    with open(\"data/preapr2018_antigens.train.txt\", \"r\") as infile:\n",
    "        train_names = set([l.strip() for l in infile.readlines()])\n",
    "    with open(\"data/preapr2018_antigens.validation.txt\", \"r\") as infile:\n",
    "        val_names = set([l.strip() for l in infile.readlines()])\n",
    "\n",
    "    X = torch.zeros(size=(n_seqs, seq_max_length, embedding_dim))\n",
    "    y = torch.zeros(size=(n_seqs, seq_max_length))\n",
    "    mask = torch.zeros(size=(n_seqs, seq_max_length))\n",
    "    test_idx = list()\n",
    "    train_idx = list()\n",
    "    val_idx = list()\n",
    "    for i, embed_dict in enumerate(list_of_dicts):\n",
    "        seq = embed_dict[SEQ_KEY_NAME]\n",
    "        pdb_id = embed_dict['pdb_id']\n",
    "        embedding = embed_dict['per_tok'].detach()\n",
    "        \n",
    "        if pdb_id in test_names:\n",
    "            test_idx.append(i)\n",
    "        elif pdb_id in train_names:\n",
    "            train_idx.append(i)\n",
    "        elif pdb_id in val_names:\n",
    "            val_idx.append(i)\n",
    "        y_ = torch.Tensor([1 if letter.isupper() else 0 for letter in seq])\n",
    "\n",
    "        X[i, 0:embedding.shape[0]] = embedding\n",
    "        y[i, 0:len(y_)] = y_\n",
    "        mask[i, 0:len(y_)] = torch.ones((1,len(y_)))\n",
    "\n",
    "    test_idx = np.asarray(test_idx)\n",
    "    train_idx = np.asarray(train_idx)\n",
    "    val_idx = np.asarray(val_idx)\n",
    "\n",
    "\n",
    "    random_indices = np.random.choice(len(train_idx), len(train_idx), replace=False)\n",
    "\n",
    "    inputs_train = X[train_idx, :, :]\n",
    "    inputs_test = X[test_idx, :, :]\n",
    "    inputs_val = X[val_idx, :, :]\n",
    "    targets_train = y[train_idx]\n",
    "    targets_test = y[test_idx]\n",
    "    targets_val = y[val_idx]\n",
    "    masks_train = mask[train_idx]\n",
    "    masks_test = mask[test_idx]\n",
    "    masks_val = mask[val_idx]\n",
    "\n",
    "    print(\"Training dims:\", inputs_train.shape, targets_train.shape)\n",
    "    print(\"Test dims:\", inputs_test.shape, targets_test.shape)\n",
    "    print(\"Validation dims:\", inputs_val.shape, targets_val.shape)\n",
    "    \n",
    "    training_set = EpitopeDataset(inputs_train.to(device), targets_train.to(device), masks_train.to(device))\n",
    "    validation_set = EpitopeDataset(inputs_val.to(device), targets_val.to(device), masks_val.to(device))\n",
    "    test_set = EpitopeDataset(inputs_test.to(device), targets_test.to(device), masks_test.to(device))\n",
    "\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "def create_positional_datasets(list_of_dicts):\n",
    "    with open(\"data/postapr2018_antigens.test.txt\", \"r\") as infile:\n",
    "        test_names = set([l.strip() for l in infile.readlines()])\n",
    "    with open(\"data/preapr2018_antigens.train.txt\", \"r\") as infile:\n",
    "        train_names = set([l.strip() for l in infile.readlines()])\n",
    "    with open(\"data/preapr2018_antigens.validation.txt\", \"r\") as infile:\n",
    "        val_names = set([l.strip() for l in infile.readlines()])\n",
    "\n",
    "    test_idx = []\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "\n",
    "    # Define partition sizes\n",
    "    y = torch.Tensor()\n",
    "    X = torch.Tensor()\n",
    "    for embed_dict in list_of_dicts:\n",
    "        seq = embed_dict[SEQ_KEY_NAME]\n",
    "        y_ = torch.Tensor([1 if letter.isupper() else 0 for letter in seq])\n",
    "        #print(seq, y)\n",
    "\n",
    "        pdb_id = embed_dict['pdb_id']\n",
    "\n",
    "        if pdb_id in test_names:\n",
    "            test_idx.extend(list(range(len(y), len(y)+len(y_))))\n",
    "        elif pdb_id in train_names:\n",
    "            train_idx.extend(list(range(len(y), len(y)+len(y_))))\n",
    "        elif pdb_id in val_names:\n",
    "            val_idx.extend(list(range(len(y), len(y)+len(y_))))\n",
    "\n",
    "\n",
    "        embedding = embed_dict['per_tok'].detach()\n",
    "        X = torch.cat((X, embedding), 0)\n",
    "        y = torch.cat((y, y_), 0)\n",
    "    \n",
    "    inputs_train = X[train_idx, :]\n",
    "    inputs_val = X[val_idx, :]\n",
    "    inputs_test = X[test_idx, :]\n",
    "    targets_train = y[train_idx]\n",
    "    targets_val = y[val_idx]\n",
    "    targets_test = y[test_idx]\n",
    "\n",
    "    # Get inputs and targets for each partition\n",
    "\n",
    "    print(\"Training dims:\", inputs_train.shape, targets_train.shape)\n",
    "    print(\"Test dims:\", inputs_test.shape, targets_test.shape)\n",
    "    print(\"Validation dims:\", inputs_val.shape, targets_val.shape)\n",
    "\n",
    "    training_set = data.TensorDataset(inputs_train.to(device), targets_train.to(device))\n",
    "    validation_set = data.TensorDataset(inputs_val.to(device), targets_val.to(device))\n",
    "    test_set = data.TensorDataset(inputs_test.to(device), targets_test.to(device))\n",
    "\n",
    "    return training_set, validation_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5678e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dicts = list()\n",
    "\n",
    "for pt in glob.glob(embedding_type+'*.pt'):\n",
    "    pt_obj = torch.load(pt)\n",
    "    embedding_dicts.append(pt_obj)\n",
    "\n",
    "fasta = {}\n",
    "with open(\"data/antigens_before_clustering.fasta\", \"r\") as file_one:\n",
    "    for line in file_one:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:]\n",
    "            if active_sequence_name not in fasta:\n",
    "                fasta[active_sequence_name] = []\n",
    "            continue\n",
    "        sequence = line\n",
    "        fasta[active_sequence_name].append(sequence)\n",
    "\n",
    "for embed_dict in embedding_dicts:\n",
    "    assert len(embed_dict[SEQ_KEY_NAME]) == len(fasta[embed_dict['pdb_id']][0])\n",
    "    embed_dict[SEQ_KEY_NAME] = fasta[embed_dict['pdb_id']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d4475",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Since we are working with amino acid residue data, there are three general approaches:\n",
    "1. Working with the data for individual residues. This doesn't preserve the structural information within the data structure, but due to the fact that ProteinSolver incorporates the structural context into each embedding, a lot of the signal should still be there.\n",
    "2. Working with the data sequentially, preserving some of the biological context along the sequence - although it does not capture all. This is sequences and RNNs.  \n",
    "3. Working with with data structurally, preserving the biological context in which the amino acid residues are observed. This is PDB files and GNN representations.\n",
    "\n",
    "\n",
    "## Individual residue model (FFNN)\n",
    "This is the simplest possible model, as it acts on each position individually. The architecture uses a batch-norm, three increasingly smaller linear layers with ReLU activation and a small amount of dropout. For this model, the RNN, and the GNN, early stopping is implemented using the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ecef14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dims: torch.Size([49181, 128]) torch.Size([49181])\n",
      "Test dims: torch.Size([26680, 128]) torch.Size([26680])\n",
      "Validation dims: torch.Size([4244, 128]) torch.Size([4244])\n"
     ]
    }
   ],
   "source": [
    "training_set, val_set, test_set = create_positional_datasets(embedding_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8cf98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_EPOCHS = 200\n",
    "LR = 1e-3\n",
    "LR_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2035f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): Sequential(\n",
      "    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): Linear(in_features=16, out_features=1, bias=False)\n",
      "    (8): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "                    nn.BatchNorm1d(128),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=0.1),\n",
    "                    nn.Linear(64, 16),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=0.1),\n",
    "                    nn.Linear(16, 1, bias=False),\n",
    "                    nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdafd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_X, train_y = training_set.tensors\n",
    "test_X, test_y = test_set.tensors\n",
    "val_X, val_y = val_set.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48fd6ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb85983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.2649185359477997, test loss 0.26786381006240845, validation loss 0.32478106021881104\n",
      "Epoch 0, training AUC 0.6747612543698802, test AUC 0.6563184323793703\n",
      "Epoch 0, training MCC 0.11547967264766935, test MCC 0.10224730599529396\n",
      "Epoch 1, training loss 0.2627163231372833, test loss 0.2666051685810089, validation loss 0.32288941740989685\n",
      "Epoch 1, training AUC 0.6851370000431881, test AUC 0.6632438312074426\n",
      "Epoch 1, training MCC 0.12830684974790837, test MCC 0.10493040226547935\n",
      "Epoch 2, training loss 0.26190996170043945, test loss 0.26675117015838623, validation loss 0.323234885931015\n",
      "Epoch 2, training AUC 0.6886527446288107, test AUC 0.6614547204832986\n",
      "Epoch 2, training MCC 0.13335274577638115, test MCC 0.1024690671040694\n",
      "Epoch 3, training loss 0.2612265348434448, test loss 0.26635581254959106, validation loss 0.3223806619644165\n",
      "Epoch 3, training AUC 0.6915946805656603, test AUC 0.6627947837234919\n",
      "Epoch 3, training MCC 0.13417273286945547, test MCC 0.10216762413596704\n",
      "Epoch 4, training loss 0.2610509991645813, test loss 0.26640117168426514, validation loss 0.32315778732299805\n",
      "Epoch 4, training AUC 0.6919967285350214, test AUC 0.6632366946742317\n",
      "Epoch 4, training MCC 0.1326831971488546, test MCC 0.10219234683776615\n",
      "Epoch 5, training loss 0.260224312543869, test loss 0.26591983437538147, validation loss 0.32224661111831665\n",
      "Epoch 5, training AUC 0.6947163583388375, test AUC 0.663815432169344\n",
      "Epoch 5, training MCC 0.1409437873601558, test MCC 0.10553560366178528\n",
      "Epoch 6, training loss 0.2599087655544281, test loss 0.2660312056541443, validation loss 0.3222290873527527\n",
      "Epoch 6, training AUC 0.695595196125915, test AUC 0.6628529746522569\n",
      "Epoch 6, training MCC 0.13823242924878598, test MCC 0.10921533099110008\n",
      "Epoch 7, training loss 0.2595341205596924, test loss 0.26575905084609985, validation loss 0.3217877447605133\n",
      "Epoch 7, training AUC 0.6973831860450167, test AUC 0.6642457737201931\n",
      "Epoch 7, training MCC 0.14220852941070067, test MCC 0.10814455749047927\n",
      "Epoch 8, training loss 0.25904616713523865, test loss 0.26534897089004517, validation loss 0.3209570050239563\n",
      "Epoch 8, training AUC 0.6986204761369366, test AUC 0.6651869267271594\n",
      "Epoch 8, training MCC 0.14700790651573933, test MCC 0.11250795745009776\n",
      "Epoch 9, training loss 0.25909069180488586, test loss 0.265691876411438, validation loss 0.32148033380508423\n",
      "Epoch 9, training AUC 0.698568578945119, test AUC 0.6634214993575401\n",
      "Epoch 9, training MCC 0.14651876278133297, test MCC 0.11520770691359118\n",
      "Epoch 10, training loss 0.25872766971588135, test loss 0.2653253376483917, validation loss 0.3215547204017639\n",
      "Epoch 10, training AUC 0.699989784119148, test AUC 0.6652502192740432\n",
      "Epoch 10, training MCC 0.14433665997016118, test MCC 0.11126571831340354\n",
      "Epoch 11, training loss 0.25876080989837646, test loss 0.26549220085144043, validation loss 0.32203784584999084\n",
      "Epoch 11, training AUC 0.7006311431442525, test AUC 0.6648587321817867\n",
      "Epoch 11, training MCC 0.1441693988855729, test MCC 0.11189008098148277\n",
      "Epoch 12, training loss 0.2585955560207367, test loss 0.26535406708717346, validation loss 0.3227421045303345\n",
      "Epoch 12, training AUC 0.701009958640296, test AUC 0.6662865929322984\n",
      "Epoch 12, training MCC 0.1465912267621799, test MCC 0.11942045642366751\n",
      "Epoch 13, training loss 0.2583157420158386, test loss 0.2652098536491394, validation loss 0.3215930163860321\n",
      "Epoch 13, training AUC 0.7022137756477007, test AUC 0.6661793634158876\n",
      "Epoch 13, training MCC 0.147637438414866, test MCC 0.11734491568701431\n",
      "Epoch 14, training loss 0.258144736289978, test loss 0.2653750479221344, validation loss 0.3218052387237549\n",
      "Epoch 14, training AUC 0.7028070172894566, test AUC 0.6648052989418289\n",
      "Epoch 14, training MCC 0.14998527808362822, test MCC 0.11712019171378496\n",
      "EARLY-STOPPING !\n",
      "Best epoch found: nÂº 8\n",
      "Exiting. . .\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss(reduction=\"none\")\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=LR_DECAY)\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "net.apply(weight_reset)\n",
    "losses=[]\n",
    "training_plot=[]\n",
    "test_plot=[]\n",
    "val_plot=[]\n",
    "auc_train_plot=[]\n",
    "auc_test_plot=[]\n",
    "mcc_train_plot=[]\n",
    "mcc_test_plot=[]\n",
    "\n",
    "last_score=np.inf\n",
    "max_es_rounds = 5\n",
    "es_rounds = max_es_rounds\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "   \n",
    "    for i, data in enumerate(trainloader,0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #scheduler.step()     \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(torch.flatten(outputs), labels.to(device))\n",
    "        loss = torch.sum(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "# print statistics\n",
    "    with torch.no_grad():\n",
    "        test_loss=0\n",
    "        train_loss=0\n",
    "        net.eval()\n",
    "        inputs, labels = train_X, train_y\n",
    "\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        loss = criterion(torch.flatten(outputs), labels)\n",
    "        loss = torch.mean(loss)\n",
    "        training_plot.append(loss.cpu().numpy())\n",
    "        auc_train_plot.append(roc_auc_score(labels.cpu(), outputs.cpu().flatten()))\n",
    "        mcc_train_plot.append(mcc(labels.cpu(), outputs.cpu().flatten()>.1))\n",
    " \n",
    "\n",
    "        inputs, labels = test_X, test_y\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(torch.flatten(outputs), labels)\n",
    "        loss = torch.mean(loss)\n",
    "        test_plot.append(loss.cpu().numpy())\n",
    "        auc_test_plot.append(roc_auc_score(labels.cpu(), outputs.cpu().flatten()))\n",
    "        fpr, tpr, _ = roc_curve(labels.cpu(), outputs.cpu().flatten())\n",
    "        mcc_test_plot.append(mcc(labels.cpu(), outputs.cpu().flatten()>.1))\n",
    "\n",
    "        inputs, labels = val_X, val_y\n",
    "        outputs = net(inputs)\n",
    "        valloss = criterion(torch.flatten(outputs), labels)\n",
    "        valloss = torch.mean(valloss)\n",
    "        val_plot.append(valloss.cpu().numpy())\n",
    "        print(\"Epoch {}, training loss {}, test loss {}, validation loss {}\".format(epoch, training_plot[-1], test_plot[-1], valloss))\n",
    "        print(\"Epoch {}, training AUC {}, test AUC {}\".format(epoch, auc_train_plot[-1], auc_test_plot[-1]))\n",
    "        print(\"Epoch {}, training MCC {}, test MCC {}\".format(epoch, mcc_train_plot[-1], mcc_test_plot[-1]))\n",
    "        \n",
    "    if EARLY_STOPPING:\n",
    "        if last_score > valloss:\n",
    "            last_score = valloss\n",
    "            best_epoch = epoch\n",
    "            es_rounds = max_es_rounds\n",
    "            best_model = copy.deepcopy(net)\n",
    "            ffnn_fpr, ffnn_tpr = fpr, tpr\n",
    "        else:\n",
    "            if es_rounds > 0:\n",
    "                es_rounds -=1\n",
    "            else:\n",
    "                print('EARLY-STOPPING !')\n",
    "                print('Best epoch found: nÂº {}'.format(best_epoch))\n",
    "                print('Exiting. . .')\n",
    "                break\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4657a048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABLmUlEQVR4nO3dd3gU1dfA8e9JIYVOKCK9F6kSKaJUKQKCioqoYAcE9EUUQQH1h1iwoCDSFETEhiiIgBQRRAWkSZPehNBrKCEhyd73j5kkm5CygWx2Nzmf59knM3fa2cnunJ17Z+6IMQallFIqLX6eDkAppZR300ShlFIqXZoolFJKpUsThVJKqXRpolBKKZUuTRRKKaXSpYkihxCRf0Wkhafj8DQRmSgiw7N5m9NEZGR2btNdRORhEVl8jcvm2M+giBgRqezpODxF9D6KrCciB4ASQDxwEVgI9DfGXPRkXDmNiDwGPGWMuc3DcUwDIowxwzwcx+tAZWPMI9mwrWl4wXvOLiJigCrGmD2ejsUT9IzCfe4yxuQD6gH1gZc9G07miUhAbty2J+k+V17JGKOvLH4BB4A7nMbfBeY7jTcGVgLngE1AC6dpRYDPgSPAWWCO07ROwEZ7uZVAnZTbBG4ELgNFnKbVB04Bgfb4E8B2e/2LgHJO8xqgH7Ab2J/G++sM/GvHsRyokSKOl4Ft9vo/B4Iz8R4GA5uBGCAAGALsBS7Y67zHnrcGEE3SWds5u3waMNIebgFEAC8AJ4CjwONO2wsDfgbOA2uBkcCf6fxfb3P6vx0CHnPa5ifAfDvOv4FKTsuNsec/D6wHbnea9jowC5hhT38KaAissrdzFBgH5HFa5iZgCXAGOA68ArQHrgCx9v7YZM9bEJhir+ew/R797WmPAX8BHwKn7WmPJewDQOxpJ+zYtgC1gF72dq7Y2/o55ece8LfjSvjfrQfKpLFfU/0+ALdifW7L2ON1sT5T1e3xVD8bqby3c8A+e32P2f+LE8CjTvNPAyba+/UC8DtXfy8q28NBwPvAQXv/TwRCPH3ccesxzdMB5MRXii9MafsLNsYeL2V/KTtgndG1sceL2dPnA98BhYFAoLldXt/+cDeyv4SP2tsJSmWbvwFPO8XzHjDRHu4C7ME60AYAw4CVTvMa+8tSJLUPP1AVuGTHHQi8ZK8vj1McW4Ey9jr+IunA7cp72GgvG2KX3Y+V/PyAbva2S9rTHiPFgZ2rE0UcMMKOtQMQBRS2p39rv0KBmlgHkFQTBVAO6wDS3V5XGFDPaZunsQ7wAcBXwLdOyz5izx+AlbSOYSdPrEQRC9xtv8cQoAHWwTMAKI+V1AfY8+fHOui/AATb442c1jUjRdyzgUlAXqA4sAbo7bT/4oBn7W2FkDxRtMM6wBfCSho1nPZ94n5O43M/COtzX81eti4Qlsp+zej78CbW5znEXl9/p2Uz+mzEAY9jfdZGYh3YP8E60Le1/5/5nN7PBaCZPX0MTp8FkieKD4G5WJ/v/Fg/Nt729HHHrcc0TweQE1/2F+ai/cEzwFKgkD1tMPBlivkXYR00SwIO7ANZinkmAG+kKNtJUiJx/pI+BfxmDwvWAbCZPf4L8KTTOvywDp7l7HEDtErnvQ0HZqZY/jBJvwIPAH2cpncA9mbiPTyRwb7dCHSxhx8j40RxGQhwmn4C6yDsj3WAruY0Lc0zCqyzpNlpTJsGfJbiPe9I5z2cBeraw68DKzJ4zwMSto2VqP5JY77XcUoUWO1kMTglfHv5ZU7772CKdSTuU6AVsMveX35p7ecUn/uEz+DOhP9TBu8tze+DPRyIlay2YLX1SSY+G7udptXG+myXcCo7TfJk75zc82GdrSaczRigMtb36RLJzxibkMbZd055aRuF+9xtjMmPdbCqDhS1y8sB94vIuYQXVpVGSaxf0meMMWdTWV854IUUy5XB+kWV0g9AExEpifULyQH84bSeMU7rOIP14S/ltPyhdN7XjcB/CSPGGIc9f1rL/+cUoyvvIdm2RaSniGx0mr8WSfvSFaeNMXFO41FYB4FiWL+inbeX3vsug1XNkZZjqWwDABF5UUS2i0ik/R4Kkvw9pHzPVUVknogcE5HzwFtO82cUh7NyWAfao077bxLWmUWq23ZmjPkNq9rrE+CEiEwWkQIubtvVONP7PmCMicU6iNcCPjD2kRlc+mwcdxq+bK8vZVk+p/HEfWGsC0/OcPX3qxjWGeh6p+0utMtzLE0UbmaM+R3rg/6+XXQI6xdUIadXXmPMO/a0IiJSKJVVHQLeTLFcqDHmm1S2eRZYjHU6/hDWLyXjtJ7eKdYTYoxZ6byKdN7SEawvNwAiIlgHhcNO85RxGi5rL+Pqe3A+EJQDPgX6Y1VbFMKq1hIX4szISayqidJpxJ3SIaBSZjciIrdjVc89gHWmWAiIJOk9wNXvYwKwA+sqmwJYdf0J8x8CKqaxuZTrOYR1RlHUaX8XMMbclM4yyVdozFhjTAOsqrmqWFVKGS6H6/srve8DIlIKeA2rresDEQmyyzP6bFyLxP+/iOTDqlo6kmKeU1gJ5ianeAsa68KVHEsTRfb4CGgjInWxGi3vEpF2IuIvIsEi0kJEShtjjmJVDY0XkcIiEigizex1fAr0EZFGYskrIh1FJH8a2/wa6AncZw8nmAi8LCI3AYhIQRG5PxPvZSbQUURai0ggVl15DFZjZIJ+IlJaRIoAQ7HaXK7lPeTFOiCdtGN9HOtXY4LjQGkRyZOJ+AEwxsQDPwKvi0ioiFTH2l9p+Qq4Q0QeEJEAEQkTkXoubCo/VkI6CQSIyKtARr/K82M1Hl+043rGado8oKSIDBCRIBHJLyKN7GnHgfIi4me/x6NYPxg+EJECIuInIpVEpLkLcSMit9j/q0Cs6pZorLPThG2llbAAPgPeEJEq9v+6joiEpTJfmt8H+0fINKzG+Cex2mbesJfL6LNxLTqIyG325+kNYLUxJtkZl30G/SnwoYgUt7ddSkTaXee2vZomimxgjDkJTAdetT94XbB+JZ7E+kU1iKT/RQ+suvMdWPXpA+x1rAOexqoKOIvVgPxYOpudC1QBjhljNjnFMhsYBXxrV2tsBe7MxHvZidU4+zHWr6u7sC4FvuI029dYB6h9WNUPI6/lPRhjtgEfYF0BdByrnvkvp1l+w7r66piInHL1PTjpj1UNdAz4EvgGK+mlFstBrLaHF7CqJDZiNdBmZBFW1cQurGq4aNKv4gJ4EetM8ALWQSkh0WKMuYDV4HuXHfduoKU9+Xv772kR2WAP9wTykHQV2izsah0XFLC3f9aO/TTWhRFgHbxr2tUvc1JZdjTWj4rFWElvClaDdDIZfB+ew6omG26fET8OPC4it7vw2bgWX2OdvZzBuqAgrftRBmN9dlfb36FfsRrtcyy94U5lKbFuNnzKGPOrp2PJLBEZBdxgjHnU07Go7CW57AbCzNIzCpVriUh1u0pERKQhVvXGbE/HpZS30TsxVW6WH6u66Uas6osPgJ88GpFSXkirnpRSSqVLq56UUkqly+eqnooWLWrKly/v6TCUUsqnrF+//pQx5ppuDPS5RFG+fHnWrVvn6TCUUsqniMh/Gc+VOq16UkoplS5NFEoppdKliUIppVS6NFEopZRKlyYKpZRS6dJEoZRSKl1uSxQiMlVETojI1jSmi4iMFZE9IrJZRG52VyxKKaWunTvvo5iG1Z309DSm34nVDXYVrGcoT7D/KqWUyqyYSIg+C3FRcG4v+CUd3q9ccaSzYMbcliiMMStEpHw6s3QBptv9zK8WkUIiUtJ+2IpSSuUOxlgH99jLcPkkXD4NjivgiIXT2+DYWvAPBhMHjjirPD4WDvwChatBfAyc3ZXm6gf93IZ/jrj6CJLUefLO7FIkf4BLhF12VaIQkV5AL4CyZctmS3BKKZWlLh6FU1th9yyIi4azO+HMDutM4Fqd2nJ1WeFqVuIxBorWolbtooz9q/y1bwMf6cLDGDMZmAwQHh6u3d0qpTwv9pJd1XMZzu0BR7x1JhB3GSL+sBJB9Dnr135cVMbrCy4CAcFw8QiUaQn+ecAvD8Scg+L1oUQDqzop4SUBkCc/5C0JAUGQpwCEhLFt20k2bDjKI4/UAaDnvYbmL0RSocKIa36rnkwUh0n+MPvSdplSSnmX2MtwbA3s/hGuXIDtX1rVQNei7B0gArWehKACUKQ65C8Lfv7XFWJUVCwjX1nKe++txN9faNy4NJUrF0FEKF++0HWt25OJYi7QX0S+xWrEjtT2CaWUV7h8Bo6vg6N/w8ZxEHUi7XkLVQLjsNoKbmhknwkEgPhBqWZQqKJVHRRS1Prl7wa//LKbfv0WsH//OQCefLIBYWFXPaL8mrktUYjIN0ALoKiIRGA9tDwQwBgzEViA9bD6PUAU1oPTlVLKfY6vh1P/WtVGR/6CqJNWA7J/sNVI7Ii1qnrOp9HRat4brIN/1a5QqDKU8OxV/YcPn2fAgEXMmrUNgDp1SjBxYkeaNCmTwZKZ486rnrpnMN0A/dy1faVULuaIg62fw8XDVsPx3p+shuPMKnuH1XZQ7g6o9cR1Vw9ltX79FvDTTzsJDQ1kxIgW/N//NSYgIOtvj/OJxmyllErT6W3W1UQRK+DERutMISM1e1gJID7GaiguXBUCQsEvEPwDITAfFChntSV4mbg4R2IyGDXqDgID/fngg7aULVvQbdvURKGU8i0xkXB0DaweAYf/TH/efKWhfn/wD4L4K1C3NwS574DqTpGR0Qwb9hu7dp1h4cKHERGqVSvK99/f7/Zta6JQSvmG1SPhr+FpT6/2oNWQXLoZVOwIoSW88owgs4wxfP/9NgYMWMjRoxfx9xc2bjxG/frXdxNdZmiiUEp5r7O7Yd98WP781dNKNrLuN7h1hFVdlAPt3XuG/v1/YeHCPQA0aVKaiRM7UadOiWyNQxOFUsp7RJ2Ak1vg2N/w59CrpxeqDA+thpCw7I8tm73//kqGD19GdHQchQoFM2rUHTz11M34+WX/WZImCqWUZx3/B/5+E3b/kPY85dvBTY9B9QezLSxPi4qKJTo6jh496vD++20pXjyvx2LRRKGU8oyNE+CvoVY3GClV7GjdpFbjIavrilzg5MlL7Nx5mttus/qzGzy4KS1alKdZs3IejkwThVIqO53eBtu/ts4gnAXms25iazzcutM5F3E4DFOn/sNLLy0hIMCPHTv6U6RICEFBAV6RJEAThVLK3aJOwN9vwb9fWHc9Owu7Ce6ZBwXLeyIyj9u69QR9+szjr7+sjrTbtKlIVFQsRYpkXfcbWUEThVIq6/37BWyaYPWVlNINt1jVSrUeh7Ktsj82L3Dp0hVGjPid0aNXExfnoESJvHz0UXu6dbsJ8cJLejVRKKWyTtQJmJDKpZsBoVCsDnT4yuokL5e7777vWbhwDyLQt284b77ZmkKFgj0dVpo0USilro8jHvbMse51uHAo+bRO30H59lZ32irR4MFNOX78IhMmdKRRo9KeDidDmiiUUpkXcx52fQ9/vpJ6F9yNh1k3wnlhNUp2i4tz8PHHf3PgwDnGjLkTgBYtyrNuXS+P3BNxLTRRKKUyJ7WuNAJCrQbpmj3hlkHWsxgUa9YcpnfveWzceAyAXr0acNNNxQF8JkmAJgqllKviYmDBw8lvjKt6HzR5DYrW8lxcXujcuWheeWUpEyeuwxgoV64g48Z1SEwSvkYThVIqffFXYOHjsOPr5OXPXYLAUM/E5MW+/XYrAwYs5PjxSwQE+PHCC00YPrwZefPm8XRo10wThVIqbbtnw9x7k5c1eAFavO+ZeHzA4sV7OX78Ek2blmHChI7Urp29Hfi5gyYKpVRysVGwtC/s/hGuXEgqr94d2n+RY3tqvVYxMXEcPnyBihULA/Duu224/fayPPpoPZ9qh0iPJgqllCU+Fn6+D/bOTV5erA50X6XVTKn47bf9PPPMfPz8hE2b+pAnjz9Fi4by+OP1PR1altJEoVRuZgxciIB178M/Y5NPy1cKHtum90Ck4vjxi7z44hJmzNgMQPXqRYmIOJ94VpHTaKJQKrc5sBh2zoSd30HsxeTTggpa9z/c/JxnYvNyDofh00/XM2TIUs6diyY4OIBhw25n0KCm5Mnj7+nw3EYThVK5gTHW/Q+bxsOlY6nP02go3DYye+PyMffc8x1z5+4EoF27SnzySQcqVSri4ajcTxOFUjld9Dn46hY4tyepzC/QapguVNF63oOfHgpcce+91Vmz5jBjxrTn/vtremUHfu6gnw6lcqLoc/Dbs1b1kiM2qTzfjdBjI4QW81RkPmXu3J1ERJynb99bAOjZsy733luD/PmDPBxZ9tJEoVROcno7zO4IkfuvntZ2CtR+Ivtj8kEHD0by3HO/8NNPOwkK8qd9+8pUrFgYEcl1SQI0USiVM8Schzl3QcSK5OXVusEtg6F4Pe2gzwWxsfGMHfs3r722nEuXYsmfPw8jR7aiXLmCng7NozRRKOXLok7AnLvh6Krk5W0mQe2ntHO+TFi9OoLeveexefNxAO6/vyYfftiOUqX08mBNFEr5otPbrDaIg78lL2/0CjR9QxPENRg+fBmbNx+nQoVCjBvXgQ4dqng6JK+hiUIpXxIbBT+0h8N/JC9vOhIaDgG/nHstf1YzxnDhwhUKFLDaHMaNu5Pp0zcxdGgzQkO1mxJnmiiU8hVH/4avGycvu3kA3PYWBIZ4JCRftXPnKfr2XYAILFnSAxGhWrWivPlma0+H5pU0USjl7RzxMKkURB1PKrvpMWg3VRuoMyk6Oo633/6Dd975iytX4gkLC+HAgXNUqJAzu97IKpoolPJW8bEwpzMcWJhUFlQQ7lsCN9ziubh81JIle+nbdwF79pwB4Ikn6vHuu20IC9PODjPi1kQhIu2BMYA/8Jkx5p0U08sCXwCF7HmGGGMWuDMmpXzC3p+tJOHsjglQt49n4vFhxhiefHIun3++EYCaNYsxcWJHbr+9nGcD8yFuSxQi4g98ArQBIoC1IjLXGLPNabZhwExjzAQRqQksAMq7KyalvN6ZnfB1I4iJTCpr8ho0fBkCct+NXllBRChfvhAhIQG8+mpzBg5skqM78HMHd55RNAT2GGP2AYjIt0AXwDlRGCDhIuWCwBE3xqOUd/vvV5jVJnnZE7uhcGXPxOPDNm48xtGjF7jzTusS18GDm9KjRx1ti7hG7rzYuhRwyGk8wi5z9jrwiIhEYJ1NPJvaikSkl4isE5F1J0+edEesSnnO+UMwt2vyJNF6PAx0aJLIpAsXYhg4cBENGkzm0UfncObMZQCCggI0SVwHTzdmdwemGWM+EJEmwJciUssY43CeyRgzGZgMEB4ebjwQp1Lu8ddwq/tvZ/3OQLAe1DLDGMOcOTt47rmFREScx89PeOih2gQG6o2HWcGdieIwUMZpvLRd5uxJoD2AMWaViAQDRYETboxLKe/wRR04tSVp/Ob/s++J0KtwMuO//87Rv/8vzJu3C4Dw8BuZNKkTN99c0sOR5RzuTBRrgSoiUgErQTwIPJRinoNAa2CaiNQAggGtW1I538LHkyeJvqchJOc/ACerGWPo2nUm69cfpUCBIN56qxV9+oTj769nElnJbYnCGBMnIv2BRViXvk41xvwrIiOAdcaYucALwKci8jxWw/ZjxhitWlI515Yp8PuLEHMuqWxgvPbNlEkOh8HPTxAR3n+/LRMnruPDD9tRsmR+T4eWI4mvHZfDw8PNunXrPB2GUplzcgvMbAHRZ5LKggtDn2Pgn8djYfma06ejGDLkVwA+/bRzBnMrZyKy3hgTfi3LeroxW6mc7eAy+L7V1eXd/oDSt2V/PD7KGMP06Zt48cUlnDoVRZ48/rz2WgtKl9YuwLODJgql3CVlkvDPY/Xyessgz8Xkg7ZvP8kzz8zn99//A6BFi/JMmNBRk0Q20kShVFaLj4UlveDfaUllXX6CylpVkhnGGF59dRmjRv1FbKyDokVD+eCDtvToUQfRzhCzlSYKpbJS1AmYUCJ52dMHoID2K5RZIsLhwxeIjXXw9NM38847d1CkiHan7gmaKJTKCic3w8yWyRuri9aC7ishj16J46ojRy5w6lQUdepYyfbdd9vw5JP1adq0rIcjy930mjylrlfkfpheN3mSaPUxPLpFk4SL4uMdjBu3hho1PuHBB2dx5Uo8AEWLhmqS8AJ6RqHU9Ti7B6Y6PVu5+yq4sXHa86urbNhwlN6957FundUnaLNm5Th/PoaiRfUOdW+hiUKpzDLGaqhe8zac3Z1U3uErTRKZcP58DMOH/8a4cWtxOAylSxdg7Nj23H13dW2s9jIuJwoRCTXGRLkzGKW8Xuxl6wziYopuyx7dCkVv8kxMPsgYQ7Nmn7Np03H8/YWBAxvz+ustyJ9fn7nhjTJsoxCRW0VkG7DDHq8rIuPdHplS3mb/QhgbmjxJdJ5tdQeuSSJTRITnn29Mw4alWLeuFx980E6ThBfLsAsPEfkbuA+Ya4ypb5dtNcbUyob4rqJdeCiPOLEJvqyXNN7geWj+vvbR5KIrV+IZPXoV/v7CoEFNAeuswuEw2oFfNnF7Fx7GmEMp6gzjr2VjSvmk2Cj45tak8d5HIJ92Ye2qP/74jz595rNt20mCgvzp2bMuJUrkQ0Tw99e2CF/gSqI4JCK3AkZEAoH/A7a7NyylvMT5Q/Cp0+WZPf7RJOGiU6eieOmlJXz++UYAqlQpwvjxHSlRIp9nA1OZ5kqi6AOMwXqM6WFgMdDXnUEp5RUOLIIf2ieNt/wIitfzVDQ+wxjDtGkbGTRoCadPXyZPHn9efvk2hgy5jeBgvdDSF7nyX6tmjHnYuUBEmgJ/uSckpTxs82ewfQZE/J5Udud0qNnDczH5mBkztnD69GVatarA+PEdqFatqKdDUtfBlUTxMXCzC2VK+baDv8H3ra8uf3IvFKqY/fH4kKioWCIjoylZMj8iwvjxHVi79ggPP1xb74nIAdJMFCLSBLgVKCYiA50mFcB6Yp1SOcfxf65OEl1+goodwE+rS9Lzyy+76ddvARUrFmbJkh6ICNWqFdWziBwkvW9AHiCfPY9zhzXnsS6XVcr3RZ2E9aNhzTvWuPjD/b9CmRYeDcsXHD58ngEDFjFr1jYA8ucP4vTpy9r1Rg6UZqIwxvwO/C4i04wx/2VjTEpljzWj4I8hycse3QJhNTwTj4+Ij3fwySdrGTbsNy5cuELevIGMGNGS555rRECA3hORE7lyTh0lIu8BNwHBCYXGmFSe76iUj/jyZjjxT9J4rSeg2XsQUsRzMfkAh8PQvPk0/vrrEAB3312dMWPaU7ZsQQ9HptzJlUTxFfAd0AnrUtlHgZPuDEopt4m9DNPrwLk91nhgXuhzVLsDd5Gfn9C2bSUOHoxk3LgOdO5czdMhqWzgShce640xDURkszGmjl221hhzS7ZEmIJ24aGuWcqrmmo/BW0mg16VkyZjDDNn/ktAgB9du9YEICYmjthYB/ny5fFwdCoz3N2FR6z996iIdASOAHp+rnzL7jkw956k8QeWQ5nmnorGJ+zde4a+fRewePFeihULpVWrChQuHEJQUABB2n9fruJKohgpIgWBF7DunygADHBnUEplqXndYee3SeMPr4UbrumHVa4QExPHe++t5M03/yA6Oo7ChYN5881WFCwYnPHCKkfKMFEYY+bZg5FAS0i8M1sp73YhAiaXSV42IAb8tcokLcuXH+CZZ+azY8cpAHr0qMP777elePG8Ho5MeVJ6N9z5Aw9g9fG00BizVUQ6Aa8AIUD97AlRqWtwbi9MqZy87LmLmiTSER/voG9fK0lUqxbGhAkdadmygqfDUl4gvTOKKUAZYA0wVkSOAOHAEGPMnGyITanMi78Cq/4Hf7+VVNbiQ2gwwGMheTOHwxAdHUdoaCD+/n5MmNCRFSv+46WXmhIUpHekK0t6n4RwoI4xxiEiwcAxoJIx5nT2hKZUJqVsiwB47F8Iq+mZeLzcli3H6dNnPtWrhzFlShcAmjcvT/Pm5T0bmPI66SWKK8YYB4AxJlpE9mmSUF7HOKw7rP98JXl50dpw3xLIW8IzcXmxS5euMGLE74wevZq4OAf795/l7NnLFC4c4unQlJdKL1FUF5HN9rAAlexxAUzCPRVKecz5/2BaLYi9mFQWmA/6nQH/QM/F5cV+/nkn/fv/wsGDkYhA377hvPlmawoV0iuaVNrSSxTa4Y3yTsbAHy/D2lFJZXWfgZsHQJGqHgvLm8XFOejWbRY//mg9nLJevRuYNKkTDRuW8nBkyhek1ymgdgSovNPYfBAXlTR+z3yrO3CVpoAAPwoWDCJfvjy88UZL+vdvqB34KZdl2IXHda1cpD3WY1T9gc+MMe+kMs8DwOuAATYZYx5Kb53ahUcudv4QfHMrXIywxgPzwZO7Ie8Nno3LS/39t7WfGjUqDcDp01FcvhxH6dIFPBmW8hB3d+FxTez7MD4B2gARwFoRmWuM2eY0TxXgZaCpMeasiBR3VzzKx+2bD7M7JY03fQMaD/NcPF7s3LloXn75VyZNWk/16kXZuLEPefL4Examz4lQ18alRCEiIUBZY8zOTKy7IbDHGLPPXse3QBdgm9M8TwOfGGPOAhhjTmRi/Sq3OLA4eZLo9geUvs1z8XgpYwzffLOVgQMXcfz4JQIC/OjcuRrx8Q70oZTqemSYKETkLuB9rCfeVRCResAIY0znDBYtBRxyGo8AGqWYp6q9jb+wPsmvG2MWuha6yhVObIQf2iWN9z0FIWEeC8db7d59mr59F/Drr/sAaNq0DBMndqJWLT1JV9fPlTOK17HODpYDGGM2ikhW3dcfAFQBWgClgRUiUtsYc855JhHpBfQCKFu2bBZtWnm109tg2k3Jy/qe1gcLpSI2Np5WraYTEXGeIkVCePfdO3j88fr4+Wn36SpruNTNuDEmUpL32e9KC/hhrC5AEpS2y5xFAH8bY2KB/SKyCytxrE22MWMmA5PBasx2YdvKl/23FGbdkbzs8Z2aJFIwxiAiBAb68+abrVi27ADvvnsHxYppB34qa7lyfdy/IvIQ4C8iVUTkY2ClC8utBaqISAURyQM8CMxNMc8crLMJRKQoVlXUPhdjVznR/oXJk0SL0TDQofdHODl+/CI9esxm5MgViWU9e9bl88+7aJJQbuFKongW63nZMcDXWN2ND8hoIWNMHNAfWARsB2YaY/4VkREiktC+sQg4LSLbgGXAIO0mJBc7tg5+vDNpvFcENHhen0BnczgMkyato3r1T5gxYzOjR6/mwoUYT4elcgFXHoV6szFmQzbFkyG9jyKHWtIHNk9KGn9iFxSu4rl4vMymTcfo02c+q1db90a0b1+ZTz7pQMWKhT0cmfIV7r6P4gMRuQGYBXxnjNl6LRtSKlWXjsFXjeDCwaSybn9okrDFxsbz8stL+eij1cTHG0qWzMeYMe25776aiJ5pqWziyhPuWtqJ4gFgkogUwEoYI90encrZ1r4HK15KXvZ8HPjpNf8JAgL8+OefYzgchmefbcgbb7TUR5KqbJepLjxEpDbwEtDNGOORR4Vp1VMOcCEC5nWDI07XRDQeDk1HeC4mL3LwYCTx8Q4qVLCqlXbvPk1kZAzh4Td6ODLly9xa9SQiNYBuQFfgNPAd8MK1bEwpfuwI+xckjRerBw+ugDz5PRaSt4iNjWfMmL957bXlNGlSmiVLeiAiVKmiNxgqz3KljWIqVnJoZ4w54uZ4VE516ThMTNF5X7upUOtxz8TjZVatOkSfPvPZvPk4AEWKhBAVFUvevPqMb+V5rrRRNMmOQFQOFRcDX4XDKadrIAqUh6f26WWvwNmzlxky5FcmT7YuLKxQoRCffNKBO+/UxnzlPdJMFCIy0xjzgIhsIfmd2PqEO+Wa+Cvw7W3Jk8QdE6Fub8/F5EViYuKoV28SBw9GEhjox6BBtzJ0aDNCQ/XpfMq7pHdG8X/2307pzKNU6mKjYKzTXcI3PQ7tPgPRh+UkCAoK4Mkn67N06X4mTOhIzZrFPB2SUqlK81trjDlqD/Y1xvzn/AL6Zk94yufERcPyF5MniRYfQvupuT5JREfH8dpry/j66y2JZa+8cjvLlz+qSUJ5NVcas9sAg1OU3ZlKmcrtYi9Zjyl11uFrqNHdM/F4kSVL9tK37wL27DlD8eJ5ueee6oSEBOrjSJVPSK+N4hmsM4eKIrLZaVJ+4C93B6Z80PyHk4bLt4M7p0No7n4ewrFjFxk4cBHffGO109x0UzEmTuxESIi2Qyjfkd4ZxdfAL8DbwBCn8gvGmDNujUr5lnP7YEqlpPHb34GGufuEMz7ewaRJ63nllaVERsYQEhLAa6815/nnm5Anj955rnxLeonCGGMOiEi/lBNEpIgmCwXAqX/hi1pJ4zUeyfVJAiA+3vDxx2uIjIyhQ4cqjBt3Z+Kd1kr5mozOKDoB67Euj3W+6N0AFd0Yl/IFxzfAjAZJ47m8PeLChRji4w2FCgWTJ48/n356F8ePX+Tee2toB37Kp6WZKIwxney/WfXYU5WTnNmZPEk8vAZuuMVz8XiQMYbZs3fw3HO/0K5dJaZM6QLAbbfpY3tVzpDhJRci0lRE8trDj4jIaBHRb0BuFvEHfF49afypfbk2SRw4cI7Onb+la9eZHD58ga1bTxIdHefpsJTKUq5cmzcBiBKRulidAe4FvnRrVMo7GQObP4XvmiWVdV8JBXPfSWdsbDyjRv1JzZqfMG/eLgoUCGLcuDtZufIJgoNduepcKd/hyic6zhhjRKQLMM4YM0VEnnR3YMrLRJ+DCcXBEZtU1nMzFKvtsZA8JSoqlsaNP2PLlhMAPPhgLUaPbkvJktoDrsqZXEkUF0TkZaAHcLuI+AF6EXhu80vPpCSRrxR0+x0KVUp/mRwqNDSQ8PAbiYqKZfz4jrRtmzv3g8o9XEkU3YCHgCeMMcfs9on33BuW8io/d4N9P1vDbadA7Sc8G082M8YwffomKlUqkthA/eGH7ciTx19vnFO5QoZtFMaYY8BXQEER6QREG2Omuz0y5R3+eBl2zUwaz2XPj9i+/SQtW37BY4/9RK9eP3PlSjwABQsGa5JQuYYrVz09AKwB7sd6bvbfInKfuwNTXuC/X2HNO9ZwkRrwgsk1z5C4fDmWYcN+o27difz++38UKxbKyy/fRmCg9s2kch9Xqp6GArcYY04AiEgx4FdgljsDUx62aSL8+ow1HFocHt/m2Xiy0cKFe+jXbwH79p0F4Omnb+add+6gSJEQD0emlGe4kij8EpKE7TSuXVarfNXip2HLZ0njD/7puViy2cWLV+jRYzanTkVRq1ZxJk7sSNOmetuQyt1cSRQLRWQR8I093g1Y4L6QlEftmpWUJEKLQ59jOb66KT7egcNhCAz0J1++PIwZ056IiPM8/3xjAgO1Az+lXHlm9iARuRe4zS6abIyZ7d6wlEec2wc/328NlwiHR9Z6Np5ssH79EXr3nkeXLtUYPrw5AA89lPvuDVEqPek9j6IK8D5QCdgCvGiMOZxdgalstvtHmNs1abztZ2nPmwOcPx/D8OG/MW7cWhwOw/nzMQwZcpueQSiVivTaGqYC84CuWD3IfpwtEansd3BZ8iRx369QvK7n4nEjYwzff/8v1auPY+zYNYjAwIGN2bChtyYJpdKQXtVTfmPMp/bwThHZkB0BqWx2djd83ypp/OkDUKCcx8JxpwsXYujWbRa//LIHgEaNSjFxYifq1bvBw5Ep5d3SSxTBIlKfpOdQhDiPG2M0cfi6mEiYWjVp/JmTEFrUc/G4Wb58eYiJiadgwSDeeecOevVqgJ9fzm6oVyorpJcojgKjncaPOY0boNVVSyjfsXUaLHK6y/qRDTkySaxY8R8lS+ajSpUwRISpUzsTHBxAiRL5PB2aUj4jvQcXtczOQFQ2MA74azj8/Vby8g5fQYn6nonJTU6diuKll5bw+ecbad26AkuW9EBEKFeukKdDU8rnaMf5ucn0unBqa/KyR7dC0Zs8E48bOByGadM2MmjQEs6cuUyePP7cfntZ4uMNAQFazaTUtXBrohCR9sAYwB/4zBjzThrzdcXqEuQWY8w6d8aUKxkDP96ZlCTy3gA9N1k31OUg//57gmeemc8ffxwEoHXrCowf35GqVcM8HJlSvs1tiUJE/IFPgDZABLBWROYaY7almC8/8H/A3+6KJdcyDtg3HxY9AZdPJZX3Oeq5mNwkMjKaxo2ncPHiFYoXz8vo0W156KHaSA6/q1yp7JBhohDrm/YwUNEYM8J+HsUNxpg1GSzaENhjjNlnr+dboAuQsne5N4BRwKDMBq/SceEwzGgAUceTyopUhx7/eC4mNzDGICIULBjM4MFNOXz4PG+91ZrChbUDP6Wyiiud+40HmgDd7fELWGcKGSkFHHIaj7DLEonIzUAZY8z89FYkIr1EZJ2IrDt58qQLm87lzh+CyaWTkkTR2tB1ITy+HQKCPRtbFjl8+Dz33TeTGTM2J5YNHXo7EyZ00iShVBZzpeqpkTHmZhH5B8AYc1ZE8lzvhu1Hqo4GHstoXmPMZGAyQHh4uLnebedoxsB3tyeNd/kJKnf2XDxZLC7OwSefrGHYsGVcvHiFDRuO8tBDtfH399NqJqXcxJVEEWu3NxhIfB6Fw4XlDgNlnMZL22UJ8gO1gOX2F/wGYK6IdNYG7WsUfwW+vQ3O/2eNt/8iRyWJtWsP06fPfDZssNpY7r67OmPHtsffX3u9V8qdXEkUY4HZQHEReRO4DxjmwnJrgSoiUgErQTyI9extAIwxkUDiHV4ishyr40FNEtdi5euw6n9J46Wbw009PRZOVrp06QqDB//K+PFrMQbKli3Ixx/fSefO1TwdmlK5givdjH8lIuuB1ljdd9xtjNnuwnJxItIfWIR1eexUY8y/IjICWGeMmXudsSsARzx81xyO/JVUVvV+6PSd52LKYgEBfvz66z78/ISBA5vw2mvNyZv3ums/lVIuEmPSr/K3r3K6ijHmoFsiykB4eLhZt05POgCI3A+f14D4mKSyfmcguLDnYsoie/eeoVChYMLCQgGr2ik4OIDatUt4ODKlfJOIrDfGhF/Lsq5U7s7H6m58PrAU2Af8ci0bU1koLho+q5iUJG57G14wPp8kYmLiGDlyBbVqTWDw4F8Ty2+5pZQmCaU8xJWqp2SP+7Ivae3rtoiUa2Y69cnY8Vuo3s1zsWSR5csP8Mwz89mxw7o5MC7OQXy8QxurlfKwTN+ZbYzZICKN3BGMctGBxXB0lTVct4/PJ4kTJy4xaNASpk/fBEC1amFMmNCRli0reDgypRS4dmf2QKdRP+Bm4IjbIlLp2/wpLOllDecrBXdM8Gw81+nUqShq1PiEM2cuExTkz9Cht/PSS00JCtL+KpXyFq58G/M7DcdhtVX84J5wVLo2jIVl/5c0/sByj4WSVYoWDaVLl2pERJxn/PiOVK5cxNMhKaVSSDdR2Dfa5TfGvJhN8ai0/Hw/7JqVNP58HPj53jOeL126wogRv9OxY1WaNbMeuTp+fEeCgvz1zmqlvFSarYQiEmCMiQeaZmM8KjVr30tKEjfcAv3P+WSS+PnnndSsOZ53311J377zcTisS7ODgwM0SSjlxdI7o1iD1R6xUUTmAt8DlxImGmN+dHNsCmDZ87DhI2u4ZGN4aJVHw7kWhw5F8n//t5DZs3cAUL/+DUya1EmfV62Uj3CljSIYOI31jGyDdXe2ATRRuNvRv5OShF8APPiHR8PJrLg4B2PH/s2rry7j0qVY8uXLw8iRLenXryEBAXrJq1K+Ir1EUdy+4mkrSQkigfbg6m4Hl8H3CfdKCDwXZSULH3L+fAxvv/0nly7F0rVrDT76qD2lSxfwdFhKqUxK78jjD+QjeYJIoInCnc7sdEoSwNP7wT/Qc/Fkwrlz0YSEBBAUFECRIiFMmtSJoCB/Onas6unQlFLXKL1EcdQYMyLbIlGWmEj4sl7SeJ+j1jOuvZwxhm++2crzzy+if/9bGD68OQD33lvDw5Eppa5XeolCWxqzW+xl+KyC1Y8TQPeVPpEkdu06Td++81m6dD8AK1YcTHxEqVLK96WXKFpnWxQKtkyBxU8ljbcaBzc28Vw8LoiOjmPUqD95660/uXIlniJFQnjvvTY89lg9TRJK5SBpJgpjzJnsDCTXMgZmd4L9C5LK7v8Nyrb0XEwuOHbsIs2afc7u3dbH5LHH6vHee20oWjTUw5EppbKab11Gk9PERsHYvEnjwWHQ6xAEhnguJheVKJGXMmUKEhDgx4QJHWnevLynQ1JKuYkmCk9xxCVPEuXbQdeFnosnAw6H4dNP19OyZQWqVg1DRPj663spXDiEPHl87y5xpZTr9K4nT4i/Ah86Pcrzpse9Okls2nSMpk2n0qfPfPr2nU/CUxFLlMinSUKpXEDPKDzh29tJvBXlnnlQsaNHw0nLxYtXeP315Xz00Wri4w033pifPn2u6UmKSikfpokiu83pAsfWWMONX/XaJDFnzg6effYXIiLO4+cnPPtsQ0aObEWBAkGeDk0plc00UWSnrdNg71xruMnrcOtrnowmTYcPn+fBB2cRExNPgwYlmTixE+HhN3o6LKWUh2iiyC57foJFj1vDxet7XZKIjY0nIMAPEaFUqQK8+WYr8uTxp2/fW/SZ1UrlcnoEyA6r34Sf7k4av2+Jx0JJzcqVh2jQYDIzZmxOLHvhhVt59tlGmiSUUpoo3G7dB/DXMGs4qCA8fRBCwjwbk+3Mmcv07v0zTZtOZcuWE4wfvy7xiiallEqgVU/uFLECfrefIhtUEJ456RW9wBpjmDFjMy+8sJiTJ6MIDPTjpZeaMnTo7dr1hlLqKpoo3CX+Cnxn9aBKYF7odxa84CB8/PhFunf/gWXLDgDQvHk5JkzoSI0axTwbmFLKa2micIeoEzChRNL4w+u8IkkAFCoUzNGjFylaNJT3329Dz5519SxCKZUuTRRZLS46eZK47S0Iq+65eIAlS/Zy880lCQsLJSgogO+/v5+SJfMRFqYd+CmlMqaN2Vnp8hkY43TwbfYuNHrZY+EcPXqB7t1/oG3bGQwe/Gtiea1axTVJKKVcpmcUWeXcPphSKWm8zSSo08sjocTHO5g0aT0vv7yU8+djCAkJoFq1MH2YkFLqmmiiyAox52FWm6TxOyZ4LEls2HCUPn3msXbtEQA6dqzCuHEdKF++kEfiUUr5Pk0U1ytlw3WPf6B4PY+EcuDAORo2/JT4eEOpUvkZO/ZO7rmnup5FKKWui1sThYi0B8YA/sBnxph3UkwfCDwFxAEngSeMMf+5M6YstXwgrP8wabztFI8lCYDy5Qvx+OP1yJ8/iP/9rwX582sHfkqp6+e2xmwR8Qc+Ae4EagLdRaRmitn+AcKNMXWAWcC77oony+1fmDxJdP4Raj+RrSEcOHCOu+76ht9/P5BYNnnyXYwe3U6ThFIqy7jzjKIhsMcYsw9ARL4FugDbEmYwxixzmn818Igb48k6p3fAj3cmjfePhKAC2bb52Nh4Ro9exf/+9zuXL8dx6lQUq1Y9CaDVTEqpLOfORFEKOOQ0HgE0Smf+J4FfUpsgIr2AXgBly5bNqviuzbYZ8EuPpPG+p7I1Sfz550H69JnHv/+eBODBB2sxenTbbNu+Uir38YrGbBF5BAgHmqc23RgzGZgMEB4e7rle6/4cCn+/lTTefVW2dfB39uxlBg1awpQp/wBQqVJhxo/vSNu2lTJYUimlro87E8VhoIzTeGm7LBkRuQMYCjQ3xsS4MZ7r888nSUmiSA3o9juEZl//SA6H4aefdhIY6MeQIbfx8su3ERLi+Q4GlVI5nzsTxVqgiohUwEoQDwIPOc8gIvWBSUB7Y8wJN8ZyfS4ehd/6W8Pl2ljPufbP4/bN7thxigoVChEUFEBYWChffXUvZcsWpHr1om7ftlJKJXDbVU/GmDigP7AI2A7MNMb8KyIjRKSzPdt7QD7gexHZKCJz3RXPNdv+DUyyHwPqnwfume/2JBEVFcvQoUupU2cC7777V2J527aVNEkopbKdW9sojDELgAUpyl51Gr7Dndu/buf2wgKnk6C7f3b78yQWLtxD377z2b//HACnTkW5dXtKKZURr2jM9krGAVMqJ433OQp5b3Db5o4cucCAAQv5/nvr6uHatYszcWInbr21TAZLKqWUe2miSM25vTCjQdL4A8vcmiR27TpNePhkLly4QmhoIK+/3pwBAxoTGOjvtm0qpZSrNFGkFBsFU6taZxQALT6EMi3cuskqVYpwyy2lyJs3kI8/vpNy5Qq5dXtKKZUZmiicxV+BsXmTxu/9BSq0z/LNnD8fw6uvLqNv31uoWjUMEWHu3AfJm9f9V1IppVRmaaJwNvuupOH7lkC5rG1rN8Ywa9Y2/u//FnL06EV27DjFwoVWryWaJJRS3koTRYJDy+G/xdZwq3FZniT27TtL//4L+OWXPQA0blyaUaO8+6IvpZQCTRSWy2dgZktrODgM6vfLslVfuRLP+++v5I03VhAdHUehQsG8805rnn66AX5+2oGfUsr7aaLY/k3yeyUe3ZKlqz90KJIRI34nJiaehx+uzQcftKVEiXxZug2llHKn3J0oTmxKniQ6zYR8Ja97tWfPXqZQoWBEhEqVijBmTHsqVy5C69YVr3vdSimV3dzWhYdP+MGpe+6+p6Ha/de1OofDMHXqP1Su/DEzZmxOLO/dO1yThFLKZ+XeRPHz/dbzrgE6fAUhRa5rdf/+e4IWLabx5JNzOXPmcmKjtVJK+brcWfW09j3YNcsaLtkIajyU/vzpiIqK5Y03fuf991cRF+egePG8fPhhO7p3r5VFwSqllGflvkSx92dY8ZI1XLY13P/rNa9q167TtGs3gwMHziECffo04K23WlO4cEgWBauUUp6XuxLFub0wx+7hPKiQdVPddShXriDBwQHUrVuCiRM70bhx6euPUXmt2NhYIiIiiI6O9nQoSqUpODiY0qVLExiYdT1d555EsWuW1S6RoNdBkMzdxxAX52DixHV0716LsLBQgoICWLjwYUqVKkBAQO5t7sktIiIiyJ8/P+XLl0cy+dlRKjsYYzh9+jQRERFUqFAhy9abO45uESuSJ4kOX0Ge/JlaxZo1h2nY8FOeffYXBg9Oqq4qV66QJolcIjo6mrCwME0SymuJCGFhYVl+1pvzzyiMA75rnjT+zIlMPes6MjKaoUN/Y/z4tRgDZcsWpEuXam4IVPkCTRLK27njM5qzE4UjzuoyPEGvCJeThDGG7777l+efX8SxYxcJCPBj4MDGvPpqc+3ATymVq+TsOpO5XSFyvzVcpSvkL+Xyops2Had79x84duwit95ahg0bejFqVBtNEsqj/P39qVevHnXr1uXmm29m5cqV17Sejz76iKio1B+z26JFC6pVq0a9evWoV68es2bNSrbthNeBAwdYvnw5IsLPP/+cuHynTp1Yvnx54rrCw8MTp61bt44WLVqkut2jR4/SqVOna3o/2cEYw3PPPUflypWpU6cOGzZsSHW+K1eu0KtXL6pWrUr16tX54YcfEqfNnDmTmjVrctNNN/HQQ0mX5Tvv286dOyeWP/zww1SrVo1atWrxxBNPEBsbC8C8efN49dVXyTbGGJ96NWjQwLjk8Epj3sd6fdXEpUXi4uKTjT///ELz6afrTXy8w7Vtqhxt27Ztng7B5M2bN3F44cKFplmzZte0nnLlypmTJ0+mOq158+Zm7dq16W47wbJly0zp0qVNo0aNEss6duxoli1blriuMmXKmAULFhhjjFm7dq1p3rx5qtt98cUXzZw5c1x+D7GxsS7PmxXmz59v2rdvbxwOh1m1apVp2LBhqvO9+uqrZujQocYYY+Lj4xP3865du0y9evXMmTNnjDHGHD9+PHGZ1PZtwjYdDodxOBzmwQcfNOPHjzfGGONwOEy9evXMpUuXUl0utc8qsM5c43E3Z1Y9xUTCN7dawyUawEMZ/+patmw/ffsuYNKkTjRrVg6A0aPbuTNK5cs+cFNbxQvG5VnPnz9P4cKFE8ffe+89Zs6cSUxMDPfccw//+9//uHTpEg888AARERHEx8czfPhwjh8/zpEjR2jZsiVFixZl2bJl1xVy3bp1iY2NZcmSJbRp0+aq6YMGDeLNN9/kzjvvTHc9P/zwAyNHjgTgwIED9OjRg0uXLgEwbtw4br31VpYvX87w4cMpXLgwO3bsYPv27QwZMoTly5cTExNDv3796N27NxcvXqRLly6cPXuW2NhYRo4cSZcuXa7rff7000/07NkTEaFx48acO3eOo0ePUrJk8v7hpk6dyo4dOwDw8/OjaNGiAHz66af069cv8X9WvHjxDLfZoUOHxOGGDRsSEREBWO0QLVq0YN68eTzwwAPX9b5ckfMSxeltMO2mpPE7Z6Q7+4kTlxg0aAnTp28CYPToVYmJQilvc/nyZerVq0d0dDRHjx7lt99+A2Dx4sXs3r2bNWvWYIyhc+fOrFixgpMnT3LjjTcyf/58ACIjIylYsCCjR49m2bJliQexlB5++GFCQqwbR5cuXUpYWFjitgEqVKjA7NmzE+cfOnQow4cPTzVRNGnShNmzZ7Ns2TLy50/9asP9+/dTuHBhgoKCAOsgumTJEoKDg9m9ezfdu3dn3bp1AGzYsIGtW7dSoUIFJk+eTMGCBVm7di0xMTE0bdqUtm3bUqZMGWbPnk2BAgU4deoUjRs3pnPnzlc19Hbr1o2dO3deFc/AgQPp2bNnsrLDhw9TpkyZxPHSpUtz+PDhZIni3LlzAAwfPpzly5dTqVIlxo0bR4kSJdi1axcATZs2JT4+ntdff5327a0naEZHRxMeHk5AQABDhgzh7rvvTrbt2NhYvvzyS8aMGZNYFh4ezh9//KGJItOizyZPEm0mQVj1VGd1OAxTpmxg8OBfOXs2mqAgf4YNa8agQbdmU7DKp2Xil39WCgkJYePGjQCsWrWKnj17snXrVhYvXszixYupX78+ABcvXmT37t3cfvvtvPDCCwwePJhOnTpx++23u7Sdr776KlnbQsptp9SsWTMA/vzzz1SnDxs2jJEjRzJq1KhUpx89epRixZIuNImNjaV///5s3LgRf3//xIMsWL+sE+4RWLx4MZs3b05sR4mMjGT37t2ULl2aV155hRUrVuDn58fhw4c5fvw4N9xwQ7Ltfvfdd+nshcyLi4sjIiKCW2+9ldGjRzN69GhefPFFvvzyS+Li4ti9ezfLly8nIiKCZs2asWXLFgoVKsR///1HqVKl2LdvH61ataJ27dpUqlQpcb19+/alWbNmyf5/xYsX58iRI1kaf1pyVqJY/UbS8MNr4IZbUp1t//6zPPLIbFauPARA27aV+OSTDlSufH0dAyqVnZo0acKpU6c4efIkxhhefvllevfufdV8GzZsYMGCBQwbNozWrVu7rRF06NChjBw5koCAqw8rrVq1YtiwYaxevTrVZUNCQpJd+//hhx9SokQJNm3ahMPhIDg4OHFa3rxJz7U3xvDxxx/Trl3yauJp06Zx8uRJ1q9fT2BgIOXLl0/13oLMnFGUKlWKQ4cOJY5HRERQqlTyC2TCwsIIDQ3l3nvvBeD+++9nypQpgHUG0qhRIwIDA6lQoQJVq1Zl9+7d3HLLLYnrqVixIi1atOCff/5JTBT/+9//OHnyJJMmTUq2rejo6MSzPnfLOVc9GQO7f7SGK3RIM0kAFCgQxK5dp7nhhnx8+21XFi58WJOE8jk7duwgPj6esLAw2rVrx9SpU7l48SJgVZOcOHGCI0eOEBoayiOPPMKgQYMSr9TJnz8/Fy5cyNJ42rZty9mzZ9m8eXOq04cNG8a7776b6rSqVaty4MCBxPHIyEhKliyJn58fX375JfHx8aku165dOyZMmJB4NdCuXbu4dOkSkZGRFC9enMDAQJYtW8Z///2X6vLfffcdGzduvOqVMkkAdO7cmenTp2OMYfXq1RQsWPCq9gkR4a677kq86mvp0qXUrFkTgLvvvjux/NSpU+zatYuKFSty9uxZYmJiEsv/+uuvxGU+++wzFi1axDfffIOfX/LD9a5du6hVK3s6H805ZxRbpsD5/8AvEO6aedXkRYv20KJFeYKCAggLC2Xu3AepWbMYBQsGp7IypbyTczuBMYYvvvgCf39/2rZty/bt22nSpAkA+fLlY8aMGezZs4dBgwbh5+dHYGAgEyZMAKBXr160b9+eG2+88bobs50NHTo0zUbjDh06JKtecpY3b14qVarEnj17qFy5Mn379qVr165Mnz6d9u3bJzuLcPbUU09x4MABbr75ZowxFCtWjDlz5vDwww9z1113Ubt2bcLDw6lePfUq6Mzo0KEDCxYsoHLlyoSGhvL5558nTqtXr15itdyoUaPo0aMHAwYMoFixYonztWvXjsWLF1OzZk38/f157733CAsLY+XKlfTu3Rs/Pz8cDgdDhgxJTBR9+vShXLlyif/Xe++9N/GMcNmyZbz99tvX/b5cIdZVU74jPDzcJDRqJXLEwYTiVhtF3T5wx4TESYcORfLccwuZM2cHb7zRkmHDmmVzxCqn2L59OzVq1PB0GDnW7NmzWb9+feKVTyptx48f56GHHmLp0qWpTk/tsyoi640x4akukIGccUbxeQ0rSQA0fROwOvAbO/ZvXn11GZcuxZIvXx6KFNHuv5XyVvfccw+nT5/2dBg+4eDBg3zwwQfZtj3fTxS7f4Rz9tPkbnoMQoqwenUEffrMY9Om4wB07VqDMWPaU6pUAc/FqZTK0FNPPeXpEHzCLbek3QbrDr6dKE7vgPndk8bbTeXvvyO49dYpGAPlyxdi3Lg76dixatrrUCoTjDHaMaDyau5oTvDdRHF6B3zdCOKvgH8Q9DsDIjRsWIp27SpTv/4NDBvWjNDQrHt4h8rdgoODOX36tHY1rryWsZ9H4Xw5cVbwzUQRfRa+aQxXzrP7ZBGe3ziK0R0uU7VqKCLC/PkP4eenX2SVtUqXLk1ERAQnT570dChKpSnhCXdZyQcThYHJZYm5fJl3fmvO27+3JibmMMGvLGXWLOtWdk0Syh0SbpRSKrdx6w13ItJeRHaKyB4RGZLK9CAR+c6e/reIlM9wpef2sXRbMep88AyvL25JTIyDxx+vx8SJ3ts9sVJK+TK33UchIv7ALqANEAGsBbobY7Y5zdMXqGOM6SMiDwL3GGO6pbfesLyFzZmoAQDUqFGUiRM7aSd+SimVgeu5j8KdZxQNgT3GmH3GmCvAt0DKWza7AF/Yw7OA1pJBK+HZqBCCA2J5661WbNzYR5OEUkq5mTvPKO4D2htjnrLHewCNjDH9nebZas8TYY/vtec5lWJdvYBe9mgtYKtbgvY9RYFTGc6VO+i+SKL7IonuiyTVjDGp9/OeAZ9ozDbGTAYmA4jIums9fcppdF8k0X2RRPdFEt0XSURkXcZzpc6dVU+HgTJO46XtslTnEZEAoCCg9/ArpZQXcWeiWAtUEZEKIpIHeBCYm2KeucCj9vB9wG/G13opVEqpHM5tVU/GmDgR6Q8sAvyBqcaYf0VkBNZDvucCU4AvRWQPcAYrmWRksrti9kG6L5Lovkii+yKJ7osk17wvfK6bcaWUUtkr5zzhTimllFtoolBKKZUur00Ubun+w0e5sC8Gisg2EdksIktFJMfehZjRvnCar6uIGBHJsZdGurIvROQB+7Pxr4h8nd0xZhcXviNlRWSZiPxjf086eCJOdxORqSJywr5HLbXpIiJj7f20WURudmnFxhive2E1fu8FKgJ5gE1AzRTz9AUm2sMPAt95Om4P7ouWQKg9/Exu3hf2fPmBFcBqINzTcXvwc1EF+AcobI8X93TcHtwXk4Fn7OGawAFPx+2mfdEMuBnYmsb0DsAvgACNgb9dWa+3nlG4pfsPH5XhvjDGLDPGRNmjq7HuWcmJXPlcALwBjAKiszO4bObKvnga+MQYcxbAGHMim2PMLq7sCwMkPOKyIHAkG+PLNsaYFVhXkKalCzDdWFYDhUSkZEbr9dZEUQo45DQeYZelOo8xJg6IBMKyJbrs5cq+cPYk1i+GnCjDfWGfSpcxxszPzsA8wJXPRVWgqoj8JSKrRaR9tkWXvVzZF68Dj4hIBLAAeDZ7QvM6mT2eAD7ShYdyjYg8AoQDzT0diyeIiB8wGnjMw6F4iwCs6qcWWGeZK0SktjHmnCeD8pDuwDRjzAci0gTr/q1axhiHpwPzBd56RqHdfyRxZV8gIncAQ4HOxpiYbIotu2W0L/JjdRq5XEQOYNXBzs2hDdqufC4igLnGmFhjzH6sbv+rZFN82cmVffEkMBPAGLMKCMbqMDC3cel4kpK3Jgrt/iNJhvtCROoDk7CSRE6th4YM9oUxJtIYU9QYU94YUx6rvaazMeaaO0PzYq58R+ZgnU0gIkWxqqL2ZWOM2cWVfXEQaA0gIjWwEkVufKbtXKCnffVTYyDSGHM0o4W8surJuK/7D5/j4r54D8gHfG+35x80xnT2WNBu4uK+yBVc3BeLgLYisg2IBwYZY3LcWbeL++IF4FMReR6rYfuxnPjDUkS+wfpxUNRuj3kNCAQwxkzEap/pAOwBooDHXVpvDtxXSimlspC3Vj0ppZTyEpoolFJKpUsThVJKqXRpolBKKZUuTRRKKaXSpYlCeSURiReRjU6v8unMezELtjdNRPbb29pg372b2XV8JiI17eFXUkxbeb0x2utJ2C9bReRnESmUwfz1cmpPqSr76OWxyiuJyEVjTL6snjeddUwD5hljZolIW+B9Y0yd61jfdceU0XpF5AtglzHmzXTmfwyrB93+WR2Lyj30jEL5BBHJZz9rY4OIbBGRq3qNFZGSIrLC6Rf37XZ5WxFZZS/7vYhkdABfAVS2lx1or2uriAywy/KKyHwR2WSXd7PLl4tIuIi8A4TYcXxlT7to//1WRDo6xTxNRO4TEX8ReU9E1trPCejtwm5Zhd2hm4g0tN/jPyKyUkSq2XcpjwC62bF0s2OfKiJr7HlT631XqeQ83X+6vvSV2gvrTuKN9ms2Vi8CBexpRbHuLE04I75o/30BGGoP+2P1/VQU68Cf1y4fDLyayvamAffZw/cDfwMNgC1AXqw73/8F6gNdgU+dli1o/12O/fyLhJic5kmI8R7gC3s4D1ZPniFAL2CYXR4ErAMqpBLnRaf39z3Q3h4vAATYw3cAP9jDjwHjnJZ/C3jEHi6E1f9TXk//v/Xl3S+v7MJDKeCyMaZewoiIBAJviUgzwIH1S7oEcMxpmbXAVHveOcaYjSLSHOtBNX/Z3Zvkwfolnpr3RGQYVh9AT2L1DTTbGHPJjuFH4HZgIfCBiIzCqq76IxPv6xdgjIgEAe2BFcaYy3Z1Vx0Ruc+eryBWB377UywfIiIb7fe/HVjiNP8XIlIFq4uKwDS23xboLCIv2uPBQFl7XUqlShOF8hUPA8WABsaYWLF6hw12nsEYs8JOJB2BaSIyGjgLLDHGdHdhG4OMMbMSRkSkdWozGWN2ifXciw7ASBFZaowZ4cqbMMZEi8hyoB3QDeshO2A9cexZY8yiDFZx2RhTT0RCsfo26geMxXpY0zJjzD12w//yNJYXoKsxZqcr8SoF2kahfEdB4ISdJFoCVz0XXKxnhR83xnwKfIb1SMjVQFMRSWhzyCsiVV3c5h/A3SISKiJ5saqN/hCRG4EoY8wMrA4ZU3vucKx9ZpOa77A6Y0s4OwHroP9MwjIiUtXeZqqM9UTD54AXJKmb/YTuoh9zmvUCVhVcgkXAs2KfXonV87BS6dJEoXzFV0C4iGwBegI7UpmnBbBJRP7B+rU+xhhzEuvA+Y2IbMaqdqruygaNMRuw2i7WYLVZfGaM+QeoDayxq4BeA0amsvhkYHNCY3YKi7EeLvWrsR7dCVZi2wZsEJGtWN3Gp3vGb8eyGeuhPO8Cb9vv3Xm5ZUDNhMZsrDOPQDu2f+1xpdKll8cqpZRKl55RKKWUSpcmCqWUUunSRKGUUipdmiiUUkqlSxOFUkqpdGmiUEoplS5NFEoppdL1/4HwzbT8Nd7lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    ffnn_fpr,\n",
    "    ffnn_tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"Best FFNN (area = %0.4f)\" % auc(ffnn_fpr, ffnn_tpr),\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1d34aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,12))\n",
    "#plt.subplot(3, 1, 1)\n",
    "#plt.title('Score per epoch')\n",
    "#plt.ylabel('Binary Cross-entropy')\n",
    "# plt.plot(list(range(len(losses))), [x[0] for x in losses], label=['Trains BCE loss'])\n",
    "#plt.plot(list(range(len(training_plot))), test_plot, label=['Test BCE loss'])\n",
    "#plt.plot(list(range(len(training_plot))), training_plot, label=['Train BCE loss'])\n",
    "#plt.plot(list(range(len(training_plot))), val_plot, label=['Validation BCE loss'])\n",
    "\n",
    "#plt.legend()\n",
    "#plt.subplot(3, 1, 2)\n",
    "#plt.ylabel('ROC-AUC Score')\n",
    "# plt.plot(list(range(len(losses))), [x[2] for x in losses], label=['Trains ROC_AUC'])\n",
    "#plt.plot(list(range(len(training_plot))), auc_test_plot, label=['Test ROC_AUC'])\n",
    "#plt.plot(list(range(len(training_plot))), auc_train_plot, label=['Train ROC_AUC'])\n",
    "\n",
    "#plt.subplot(3, 1, 3)\n",
    "#plt.ylabel('MCC Score')\n",
    "# plt.plot(list(range(len(losses))), [x[2] for x in losses], label=['Trains ROC_AUC'])\n",
    "#plt.plot(list(range(len(training_plot))), mcc_test_plot, label=['Test MCC'])\n",
    "#plt.plot(list(range(len(training_plot))), mcc_train_plot, label=['Train MCC'])\n",
    "\n",
    "#plt.xlabel('Epoch')\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbc3e8",
   "metadata": {},
   "source": [
    "## Sequential model (RNN)\n",
    "This is a slightly more advanced model, as it acts along each sequence. The architecture uses a bidirectional simple RNN plus a single linear layer with dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04409066",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_EPOCHS = 200\n",
    "LR = 1e-4\n",
    "LR_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a376b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dims: torch.Size([216, 927, 128]) torch.Size([216, 927])\n",
      "Test dims: torch.Size([117, 927, 128]) torch.Size([117, 927])\n",
      "Validation dims: torch.Size([24, 927, 128]) torch.Size([24, 927])\n"
     ]
    }
   ],
   "source": [
    "training_set, val_set, test_set = create_sequential_datasets(embedding_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c39aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN(\n",
      "  (rnn): RNN(128, 32, batch_first=True, bidirectional=True)\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (out): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        #self.bn_input = nn.BatchNorm1d(927)\n",
    "\n",
    "        self.n_layers = 1\n",
    "        self.hidden_dim = 32\n",
    "\n",
    "        #self.rnn = nn.RNN(input_size, self.hidden_dim, self.n_layers, batch_first=True)\n",
    "        self.rnn = nn.RNN(input_size, self.hidden_dim, self.n_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "    \n",
    "        self.dense = nn.Sequential(\n",
    "                                    nn.Linear(in_features=2*self.hidden_dim, out_features=1)\n",
    "#                                    nn.Linear(in_features=2*self.hidden_dim, out_features=self.hidden_dim),\n",
    "#                                    nn.ReLU(),\n",
    "#                                    nn.Linear(in_features=self.hidden_dim, out_features=int(self.hidden_dim/2)),\n",
    "#                                    nn.ReLU(),\n",
    "#                                    nn.Linear(in_features=int(self.hidden_dim/2), out_features=int(self.hidden_dim/4)), \n",
    "#                                    nn.ReLU(),\n",
    "#                                    nn.Linear(in_features=int(self.hidden_dim/4), out_features=1),\n",
    "                                    )\n",
    "        # Dense out\n",
    "        #self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.bn_input(x)\n",
    "    \n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(4)\n",
    "\n",
    "        # Convolutional modules\n",
    "        x, hidden = self.rnn(x)\n",
    "        #x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output MLP\n",
    "        x = self.dense(x)\n",
    "\n",
    "        # Output sigmoid\n",
    "        out = self.out(x)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden\n",
    "\n",
    "net = SimpleRNN(128)\n",
    "net.to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333d21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acf2801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0, training loss 0.6574426889419556, test loss 0.6602127552032471, validation loss 0.6607173085212708\n",
      "Epoch 0, training AUC 0.4873915425411289, test AUC 0.48808593517131194\n",
      "Epoch 0, training MCC 0.0, test MCC 0.0\n",
      "Epoch 1, training loss 0.5533124208450317, test loss 0.555828332901001, validation loss 0.5642754435539246\n",
      "Epoch 1, training AUC 0.5005178140883696, test AUC 0.49986630703379775\n",
      "Epoch 1, training MCC 0.0, test MCC 0.0\n",
      "Epoch 2, training loss 0.4769001007080078, test loss 0.4789983928203583, validation loss 0.49463534355163574\n",
      "Epoch 2, training AUC 0.513172952884398, test AUC 0.5109877485500705\n",
      "Epoch 2, training MCC 0.0, test MCC 0.0\n",
      "Epoch 3, training loss 0.42088717222213745, test loss 0.42264866828918457, validation loss 0.44458407163619995\n",
      "Epoch 3, training AUC 0.524801518182413, test AUC 0.5207148051021379\n",
      "Epoch 3, training MCC 0.0013292540723099397, test MCC 0.0\n",
      "Epoch 4, training loss 0.3798176646232605, test loss 0.38135257363319397, validation loss 0.40874117612838745\n",
      "Epoch 4, training AUC 0.5349071775713213, test AUC 0.5288696174680627\n",
      "Epoch 4, training MCC 0.0037599658693447187, test MCC 0.002551666468551323\n",
      "Epoch 5, training loss 0.35004323720932007, test loss 0.35140419006347656, validation loss 0.3835420310497284\n",
      "Epoch 5, training AUC 0.5437644125923591, test AUC 0.5363580954539883\n",
      "Epoch 5, training MCC 0.015339372393789484, test MCC 0.010158614313357607\n",
      "Epoch 6, training loss 0.32864734530448914, test loss 0.3298889696598053, validation loss 0.3661503791809082\n",
      "Epoch 6, training AUC 0.5513187490393103, test AUC 0.5430583829941782\n",
      "Epoch 6, training MCC 0.027099678448592585, test MCC 0.020926677559852034\n",
      "Epoch 7, training loss 0.3134899437427521, test loss 0.3146781623363495, validation loss 0.3544026017189026\n",
      "Epoch 7, training AUC 0.557759638219328, test AUC 0.5488419651692851\n",
      "Epoch 7, training MCC 0.041092366067510266, test MCC 0.032930470598158616\n",
      "Epoch 8, training loss 0.3027719259262085, test loss 0.30396053194999695, validation loss 0.34652188420295715\n",
      "Epoch 8, training AUC 0.5634765296769653, test AUC 0.5540314094590038\n",
      "Epoch 8, training MCC 0.05196599352037732, test MCC 0.04343101927685333\n",
      "Epoch 9, training loss 0.2951550781726837, test loss 0.2963672876358032, validation loss 0.3412812054157257\n",
      "Epoch 9, training AUC 0.5688875264342099, test AUC 0.5588970729628455\n",
      "Epoch 9, training MCC 0.0573656226867927, test MCC 0.04734422350170315\n",
      "Epoch 10, training loss 0.2897016704082489, test loss 0.2909472584724426, validation loss 0.33779680728912354\n",
      "Epoch 10, training AUC 0.5741639170456986, test AUC 0.5636489340789925\n",
      "Epoch 10, training MCC 0.06344181154090185, test MCC 0.051802676482963356\n",
      "Epoch 11, training loss 0.2857533097267151, test loss 0.28703299164772034, validation loss 0.3354417383670807\n",
      "Epoch 11, training AUC 0.5792751089500986, test AUC 0.5682602045355257\n",
      "Epoch 11, training MCC 0.06339296633991345, test MCC 0.05044231321379046\n",
      "Epoch 12, training loss 0.2828339636325836, test loss 0.2841354310512543, validation loss 0.33380022644996643\n",
      "Epoch 12, training AUC 0.5843117220016013, test AUC 0.5730637792450737\n",
      "Epoch 12, training MCC 0.06377763411640744, test MCC 0.05443439473980826\n",
      "Epoch 13, training loss 0.2806352376937866, test loss 0.2819591462612152, validation loss 0.3326185345649719\n",
      "Epoch 13, training AUC 0.5891575825925527, test AUC 0.5776722696063401\n",
      "Epoch 13, training MCC 0.07031628842876407, test MCC 0.05457702112085763\n",
      "Epoch 14, training loss 0.27892443537712097, test loss 0.28026941418647766, validation loss 0.3316919505596161\n",
      "Epoch 14, training AUC 0.5939299294216177, test AUC 0.582258691170127\n",
      "Epoch 14, training MCC 0.07121054830423902, test MCC 0.05980719832839246\n",
      "Epoch 15, training loss 0.2775688171386719, test loss 0.27893301844596863, validation loss 0.330978125333786\n",
      "Epoch 15, training AUC 0.5984625661370933, test AUC 0.5866094065125232\n",
      "Epoch 15, training MCC 0.07460367326638516, test MCC 0.06626290952054822\n",
      "Epoch 16, training loss 0.27648812532424927, test loss 0.2778777778148651, validation loss 0.3303714990615845\n",
      "Epoch 16, training AUC 0.6028209719488864, test AUC 0.590783991833131\n",
      "Epoch 16, training MCC 0.07807415901987251, test MCC 0.07053248324954912\n",
      "Epoch 17, training loss 0.275596022605896, test loss 0.27700355648994446, validation loss 0.32985198497772217\n",
      "Epoch 17, training AUC 0.6068734549576215, test AUC 0.5947107760848982\n",
      "Epoch 17, training MCC 0.08009551898244256, test MCC 0.07560598233164863\n",
      "Epoch 18, training loss 0.27484723925590515, test loss 0.27628180384635925, validation loss 0.3294132947921753\n",
      "Epoch 18, training AUC 0.6106354182340927, test AUC 0.5982757467011065\n",
      "Epoch 18, training MCC 0.08258868037939229, test MCC 0.076178187114078\n",
      "Epoch 19, training loss 0.2741983234882355, test loss 0.2756565511226654, validation loss 0.32901236414909363\n",
      "Epoch 19, training AUC 0.6143336025119016, test AUC 0.6018001718729412\n",
      "Epoch 19, training MCC 0.08772116402659833, test MCC 0.0767625301648348\n",
      "Epoch 20, training loss 0.273635596036911, test loss 0.27511781454086304, validation loss 0.3286105692386627\n",
      "Epoch 20, training AUC 0.6179140731560037, test AUC 0.6052183515483391\n",
      "Epoch 20, training MCC 0.09110035731444122, test MCC 0.07926516148896501\n",
      "Epoch 21, training loss 0.2731342613697052, test loss 0.2746466100215912, validation loss 0.32825765013694763\n",
      "Epoch 21, training AUC 0.6212180754004399, test AUC 0.6083190558085687\n",
      "Epoch 21, training MCC 0.09198488467179372, test MCC 0.08030060802698025\n",
      "Epoch 22, training loss 0.27268439531326294, test loss 0.27422651648521423, validation loss 0.32791197299957275\n",
      "Epoch 22, training AUC 0.6243751512906981, test AUC 0.6113427007958677\n",
      "Epoch 22, training MCC 0.09594110062269055, test MCC 0.08386278618751332\n",
      "Epoch 23, training loss 0.27226558327674866, test loss 0.2738429605960846, validation loss 0.32760632038116455\n",
      "Epoch 23, training AUC 0.6273187818182591, test AUC 0.6140932181419807\n",
      "Epoch 23, training MCC 0.09673060694200403, test MCC 0.08798351655513055\n",
      "Epoch 24, training loss 0.2718852758407593, test loss 0.2734978497028351, validation loss 0.32728108763694763\n",
      "Epoch 24, training AUC 0.6301111638017349, test AUC 0.6167156886947531\n",
      "Epoch 24, training MCC 0.09908894991023594, test MCC 0.08953210427596053\n",
      "Epoch 25, training loss 0.27152884006500244, test loss 0.2731820046901703, validation loss 0.3269438147544861\n",
      "Epoch 25, training AUC 0.6327723147695447, test AUC 0.6191844992740799\n",
      "Epoch 25, training MCC 0.10104497143066941, test MCC 0.09285932299984222\n",
      "Epoch 26, training loss 0.2711946964263916, test loss 0.2729049623012543, validation loss 0.3266483545303345\n",
      "Epoch 26, training AUC 0.6352760036939942, test AUC 0.6213670555768367\n",
      "Epoch 26, training MCC 0.10437438968344158, test MCC 0.09271281992616404\n",
      "Epoch 27, training loss 0.2708747684955597, test loss 0.27263572812080383, validation loss 0.32639363408088684\n",
      "Epoch 27, training AUC 0.6376731245017537, test AUC 0.6234464426397752\n",
      "Epoch 27, training MCC 0.10670978877473263, test MCC 0.09595323515351858\n",
      "Epoch 28, training loss 0.2705722749233246, test loss 0.2723863422870636, validation loss 0.32610440254211426\n",
      "Epoch 28, training AUC 0.640041378251824, test AUC 0.6255211579962343\n",
      "Epoch 28, training MCC 0.10849131559138722, test MCC 0.09729907858432417\n",
      "Epoch 29, training loss 0.27028244733810425, test loss 0.27214640378952026, validation loss 0.32585686445236206\n",
      "Epoch 29, training AUC 0.6422825433190781, test AUC 0.6274551489427919\n",
      "Epoch 29, training MCC 0.11113397325395975, test MCC 0.09703142724209692\n",
      "Epoch 30, training loss 0.2700086832046509, test loss 0.2719239890575409, validation loss 0.3255824148654938\n",
      "Epoch 30, training AUC 0.644547331486696, test AUC 0.6294273160429114\n",
      "Epoch 30, training MCC 0.11239570444140438, test MCC 0.0999330828752031\n",
      "Epoch 31, training loss 0.26973357796669006, test loss 0.27170729637145996, validation loss 0.32535263895988464\n",
      "Epoch 31, training AUC 0.6466704428779944, test AUC 0.6311586944107054\n",
      "Epoch 31, training MCC 0.11343930110254526, test MCC 0.1002680056841076\n",
      "Epoch 32, training loss 0.26946404576301575, test loss 0.2714936435222626, validation loss 0.3251289129257202\n",
      "Epoch 32, training AUC 0.6486842377119467, test AUC 0.6328424767832429\n",
      "Epoch 32, training MCC 0.11395187257458657, test MCC 0.10017637321324681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, training loss 0.26920509338378906, test loss 0.2712950110435486, validation loss 0.3249036967754364\n",
      "Epoch 33, training AUC 0.65059628403629, test AUC 0.6343946679798143\n",
      "Epoch 33, training MCC 0.11376063249604415, test MCC 0.10111544878659233\n",
      "Epoch 34, training loss 0.2689541280269623, test loss 0.27111223340034485, validation loss 0.32465365529060364\n",
      "Epoch 34, training AUC 0.6525216313520708, test AUC 0.6358609246165035\n",
      "Epoch 34, training MCC 0.11569415982778461, test MCC 0.10226989736656633\n",
      "Epoch 35, training loss 0.2687055468559265, test loss 0.27092620730400085, validation loss 0.32443660497665405\n",
      "Epoch 35, training AUC 0.6543594276246996, test AUC 0.6372570101200817\n",
      "Epoch 35, training MCC 0.1177185782125159, test MCC 0.10448255274821237\n",
      "Epoch 36, training loss 0.26846325397491455, test loss 0.2707383632659912, validation loss 0.3242330849170685\n",
      "Epoch 36, training AUC 0.656190774335666, test AUC 0.6387701940005889\n",
      "Epoch 36, training MCC 0.11872907742451264, test MCC 0.10520044168231316\n",
      "Epoch 37, training loss 0.26822540163993835, test loss 0.2705645263195038, validation loss 0.3240349590778351\n",
      "Epoch 37, training AUC 0.6579038032056237, test AUC 0.6401087286660648\n",
      "Epoch 37, training MCC 0.12013631950717606, test MCC 0.10514431278819661\n",
      "Epoch 38, training loss 0.26799413561820984, test loss 0.2704054117202759, validation loss 0.3238075077533722\n",
      "Epoch 38, training AUC 0.6596267523163959, test AUC 0.6413290185235742\n",
      "Epoch 38, training MCC 0.12191226041323319, test MCC 0.10665214079656642\n",
      "Epoch 39, training loss 0.26776474714279175, test loss 0.2702523469924927, validation loss 0.32359522581100464\n",
      "Epoch 39, training AUC 0.661258974782849, test AUC 0.6424567054139977\n",
      "Epoch 39, training MCC 0.12216296199349644, test MCC 0.10887669146247479\n",
      "Epoch 40, training loss 0.26753535866737366, test loss 0.2700963020324707, validation loss 0.3234183192253113\n",
      "Epoch 40, training AUC 0.6628783318491754, test AUC 0.6435672436068127\n",
      "Epoch 40, training MCC 0.12348654421281931, test MCC 0.11086199190901402\n",
      "Epoch 41, training loss 0.26730871200561523, test loss 0.2699495851993561, validation loss 0.32323673367500305\n",
      "Epoch 41, training AUC 0.6644509317011486, test AUC 0.6445769818506211\n",
      "Epoch 41, training MCC 0.12576874306604188, test MCC 0.11246779207269708\n",
      "Epoch 42, training loss 0.2670864760875702, test loss 0.2697993218898773, validation loss 0.3230727016925812\n",
      "Epoch 42, training AUC 0.6659265576863297, test AUC 0.6455613362005319\n",
      "Epoch 42, training MCC 0.12797557358681044, test MCC 0.11224973949760544\n",
      "Epoch 43, training loss 0.26687008142471313, test loss 0.26965221762657166, validation loss 0.32286372780799866\n",
      "Epoch 43, training AUC 0.667396577189804, test AUC 0.6465977958411151\n",
      "Epoch 43, training MCC 0.1292533710391725, test MCC 0.11298903023303812\n",
      "Epoch 44, training loss 0.26666101813316345, test loss 0.26951974630355835, validation loss 0.32263028621673584\n",
      "Epoch 44, training AUC 0.6688122433285228, test AUC 0.6475467254719551\n",
      "Epoch 44, training MCC 0.12879601195859855, test MCC 0.11518660962440745\n",
      "Epoch 45, training loss 0.26645007729530334, test loss 0.2693924009799957, validation loss 0.32240810990333557\n",
      "Epoch 45, training AUC 0.6702299974952657, test AUC 0.6484117172436374\n",
      "Epoch 45, training MCC 0.12949751207840518, test MCC 0.1148353090501172\n",
      "Epoch 46, training loss 0.2662400007247925, test loss 0.26925384998321533, validation loss 0.322210431098938\n",
      "Epoch 46, training AUC 0.6715308389542598, test AUC 0.6493218783982126\n",
      "Epoch 46, training MCC 0.13012000363946727, test MCC 0.11578944982392733\n",
      "Epoch 47, training loss 0.26603198051452637, test loss 0.2691275477409363, validation loss 0.32202988862991333\n",
      "Epoch 47, training AUC 0.6728301488180009, test AUC 0.6501667503051799\n",
      "Epoch 47, training MCC 0.13234228131032463, test MCC 0.11610078537881661\n",
      "Epoch 48, training loss 0.265822172164917, test loss 0.26900213956832886, validation loss 0.3218383491039276\n",
      "Epoch 48, training AUC 0.6742144214694291, test AUC 0.6510426522789062\n",
      "Epoch 48, training MCC 0.13377257526019576, test MCC 0.11606292805143482\n",
      "Epoch 49, training loss 0.2656085193157196, test loss 0.26886841654777527, validation loss 0.3216577470302582\n",
      "Epoch 49, training AUC 0.6754590210645662, test AUC 0.6518845243579909\n",
      "Epoch 49, training MCC 0.1350248124746745, test MCC 0.11780292878698631\n",
      "Epoch 50, training loss 0.2654021382331848, test loss 0.2687377631664276, validation loss 0.3214859664440155\n",
      "Epoch 50, training AUC 0.6767781742202021, test AUC 0.6527726262686787\n",
      "Epoch 50, training MCC 0.13553549337382223, test MCC 0.11825485103897113\n",
      "Epoch 51, training loss 0.26519906520843506, test loss 0.26861393451690674, validation loss 0.3212623596191406\n",
      "Epoch 51, training AUC 0.678075536569245, test AUC 0.6535849873021298\n",
      "Epoch 51, training MCC 0.13660933656368437, test MCC 0.1188096101833468\n",
      "Epoch 52, training loss 0.2649959623813629, test loss 0.26848334074020386, validation loss 0.32108184695243835\n",
      "Epoch 52, training AUC 0.6792608620229508, test AUC 0.6543587231631958\n",
      "Epoch 52, training MCC 0.13779377274891474, test MCC 0.1188096101833468\n",
      "Epoch 53, training loss 0.2647998332977295, test loss 0.26836857199668884, validation loss 0.32086455821990967\n",
      "Epoch 53, training AUC 0.6803816384649677, test AUC 0.655060539583818\n",
      "Epoch 53, training MCC 0.13870920824647243, test MCC 0.12245069327893271\n",
      "Epoch 54, training loss 0.2646060585975647, test loss 0.2682589888572693, validation loss 0.32066309452056885\n",
      "Epoch 54, training AUC 0.6815704402183582, test AUC 0.6557641998476929\n",
      "Epoch 54, training MCC 0.13954072080547644, test MCC 0.12156774299784166\n",
      "Epoch 55, training loss 0.264419287443161, test loss 0.26815497875213623, validation loss 0.320511132478714\n",
      "Epoch 55, training AUC 0.6826245992925278, test AUC 0.6563843235032731\n",
      "Epoch 55, training MCC 0.14088654418029645, test MCC 0.12274565298831011\n",
      "Epoch 56, training loss 0.2642265558242798, test loss 0.26804521679878235, validation loss 0.3203332722187042\n",
      "Epoch 56, training AUC 0.6836810936981752, test AUC 0.6570566097710776\n",
      "Epoch 56, training MCC 0.14336655629330725, test MCC 0.1231209440206239\n",
      "Epoch 57, training loss 0.26403751969337463, test loss 0.26793745160102844, validation loss 0.3201635777950287\n",
      "Epoch 57, training AUC 0.6848575864842098, test AUC 0.6578151745280756\n",
      "Epoch 57, training MCC 0.14418943666106515, test MCC 0.12319466969257804\n",
      "Epoch 58, training loss 0.2638499438762665, test loss 0.2678377032279968, validation loss 0.3199869394302368\n",
      "Epoch 58, training AUC 0.685883024634549, test AUC 0.658428066114525\n",
      "Epoch 58, training MCC 0.14488992428587247, test MCC 0.12295568523779477\n",
      "Epoch 59, training loss 0.26366570591926575, test loss 0.26772671937942505, validation loss 0.31983140110969543\n",
      "Epoch 59, training AUC 0.6869735710396145, test AUC 0.6590810732337089\n",
      "Epoch 59, training MCC 0.14569794033579603, test MCC 0.12240416115441259\n",
      "Epoch 60, training loss 0.2634906768798828, test loss 0.26763656735420227, validation loss 0.3196460008621216\n",
      "Epoch 60, training AUC 0.6880498272394276, test AUC 0.6597176195139072\n",
      "Epoch 60, training MCC 0.14607250327798035, test MCC 0.12268900634842513\n",
      "Epoch 61, training loss 0.2633112370967865, test loss 0.2675432860851288, validation loss 0.31945183873176575\n",
      "Epoch 61, training AUC 0.6890326533185301, test AUC 0.6602788930428756\n",
      "Epoch 61, training MCC 0.1474305422441051, test MCC 0.1226565298226245\n",
      "Epoch 62, training loss 0.2631249725818634, test loss 0.26743778586387634, validation loss 0.31930577754974365\n",
      "Epoch 62, training AUC 0.6900000622755059, test AUC 0.6608519174899825\n",
      "Epoch 62, training MCC 0.1488092530607755, test MCC 0.12264331512800951\n",
      "Epoch 63, training loss 0.2629542946815491, test loss 0.2673601806163788, validation loss 0.31911081075668335\n",
      "Epoch 63, training AUC 0.6909905744335396, test AUC 0.6614020801914753\n",
      "Epoch 63, training MCC 0.14777953772987776, test MCC 0.12546429616253088\n",
      "Epoch 64, training loss 0.2627691924571991, test loss 0.26724565029144287, validation loss 0.318996787071228\n",
      "Epoch 64, training AUC 0.6919063672253499, test AUC 0.6620144654375499\n",
      "Epoch 64, training MCC 0.14811309845225454, test MCC 0.12673567185426285\n",
      "Epoch 65, training loss 0.2625904679298401, test loss 0.26716023683547974, validation loss 0.3188686966896057\n",
      "Epoch 65, training AUC 0.6928189254003961, test AUC 0.6625276557380707\n",
      "Epoch 65, training MCC 0.14844622457306664, test MCC 0.12698855117978128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, training loss 0.2624293863773346, test loss 0.2670677602291107, validation loss 0.3187100291252136\n",
      "Epoch 66, training AUC 0.6937685341292367, test AUC 0.6631835384884414\n",
      "Epoch 66, training MCC 0.15020871172084765, test MCC 0.1276378167747692\n",
      "Epoch 67, training loss 0.26226070523262024, test loss 0.2669896185398102, validation loss 0.3185802400112152\n",
      "Epoch 67, training AUC 0.6946694296982266, test AUC 0.6636479959162598\n",
      "Epoch 67, training MCC 0.15090160295944685, test MCC 0.1266950377773645\n",
      "Epoch 68, training loss 0.26208755373954773, test loss 0.2668848931789398, validation loss 0.31842494010925293\n",
      "Epoch 68, training AUC 0.6954904040976655, test AUC 0.6642434617509334\n",
      "Epoch 68, training MCC 0.1510290540428906, test MCC 0.12662617960647501\n",
      "Epoch 69, training loss 0.261913537979126, test loss 0.2667953073978424, validation loss 0.318317711353302\n",
      "Epoch 69, training AUC 0.6963799461899159, test AUC 0.6647212559931593\n",
      "Epoch 69, training MCC 0.15118081682529827, test MCC 0.12718244489697475\n",
      "Epoch 70, training loss 0.26175060868263245, test loss 0.26671501994132996, validation loss 0.31816595792770386\n",
      "Epoch 70, training AUC 0.6972277979783482, test AUC 0.6651677813288267\n",
      "Epoch 70, training MCC 0.15204058070401888, test MCC 0.12784046134162114\n",
      "Epoch 71, training loss 0.2615976333618164, test loss 0.26665058732032776, validation loss 0.31797707080841064\n",
      "Epoch 71, training AUC 0.6980452230111727, test AUC 0.6656222456994314\n",
      "Epoch 71, training MCC 0.15323700057571915, test MCC 0.12873255565431363\n",
      "Epoch 72, training loss 0.261432409286499, test loss 0.2665843665599823, validation loss 0.3178991675376892\n",
      "Epoch 72, training AUC 0.6988829325477357, test AUC 0.6659634904514522\n",
      "Epoch 72, training MCC 0.1536163301802369, test MCC 0.12933026173662915\n",
      "Epoch 73, training loss 0.2612670958042145, test loss 0.2664929926395416, validation loss 0.31772705912590027\n",
      "Epoch 73, training AUC 0.699754230389741, test AUC 0.666472410296357\n",
      "Epoch 73, training MCC 0.15503442324590477, test MCC 0.13000596657568353\n",
      "Epoch 74, training loss 0.26110005378723145, test loss 0.2664111852645874, validation loss 0.31768208742141724\n",
      "Epoch 74, training AUC 0.7004727424718749, test AUC 0.666859903987165\n",
      "Epoch 74, training MCC 0.1558531089452286, test MCC 0.13101878315962584\n",
      "Epoch 75, training loss 0.26094791293144226, test loss 0.26632916927337646, validation loss 0.3175599277019501\n",
      "Epoch 75, training AUC 0.7011822954243443, test AUC 0.6673688238320696\n",
      "Epoch 75, training MCC 0.15633581470733723, test MCC 0.1294249981620093\n",
      "Epoch 76, training loss 0.2607872486114502, test loss 0.2662506401538849, validation loss 0.3174648880958557\n",
      "Epoch 76, training AUC 0.7019604666544229, test AUC 0.6678293165192152\n",
      "Epoch 76, training MCC 0.15649551601860132, test MCC 0.1305802934869225\n",
      "Epoch 77, training loss 0.2606280744075775, test loss 0.26618918776512146, validation loss 0.31737369298934937\n",
      "Epoch 77, training AUC 0.7026660796132317, test AUC 0.6681282579659378\n",
      "Epoch 77, training MCC 0.1571536596766187, test MCC 0.13068117698938547\n",
      "Epoch 78, training loss 0.26046961545944214, test loss 0.2661248445510864, validation loss 0.3172358274459839\n",
      "Epoch 78, training AUC 0.703444118760784, test AUC 0.6684309730814935\n",
      "Epoch 78, training MCC 0.15870564483492816, test MCC 0.13042547778341637\n",
      "Epoch 79, training loss 0.26032155752182007, test loss 0.2660738527774811, validation loss 0.3170856833457947\n",
      "Epoch 79, training AUC 0.7040931470032207, test AUC 0.6686885283677482\n",
      "Epoch 79, training MCC 0.1584463502101675, test MCC 0.13110051638157197\n",
      "Epoch 80, training loss 0.26017093658447266, test loss 0.26601284742355347, validation loss 0.3169822692871094\n",
      "Epoch 80, training AUC 0.7047893568102549, test AUC 0.6690154427317954\n",
      "Epoch 80, training MCC 0.15892176765586058, test MCC 0.13127774864945507\n",
      "Epoch 81, training loss 0.2600109577178955, test loss 0.26593923568725586, validation loss 0.3168519139289856\n",
      "Epoch 81, training AUC 0.7054860865165953, test AUC 0.6693989621283385\n",
      "Epoch 81, training MCC 0.16000225392240952, test MCC 0.1321876390096855\n",
      "Epoch 82, training loss 0.2598428726196289, test loss 0.26584818959236145, validation loss 0.3168240785598755\n",
      "Epoch 82, training AUC 0.7061737840263417, test AUC 0.6698118588202276\n",
      "Epoch 82, training MCC 0.1604304302171372, test MCC 0.13189584275642777\n",
      "Epoch 83, training loss 0.2596994638442993, test loss 0.2658090591430664, validation loss 0.31667762994766235\n",
      "Epoch 83, training AUC 0.7068269798940269, test AUC 0.6700134109502813\n",
      "Epoch 83, training MCC 0.1620120451169974, test MCC 0.13171512893126894\n",
      "Epoch 84, training loss 0.2595541477203369, test loss 0.2657685875892639, validation loss 0.3165493607521057\n",
      "Epoch 84, training AUC 0.7074987207104748, test AUC 0.6702209531825079\n",
      "Epoch 84, training MCC 0.16174002238046833, test MCC 0.1310352264845621\n",
      "Epoch 85, training loss 0.25939223170280457, test loss 0.26568761467933655, validation loss 0.31651660799980164\n",
      "Epoch 85, training AUC 0.7081424881339868, test AUC 0.6705578128358087\n",
      "Epoch 85, training MCC 0.1616532195129392, test MCC 0.131727836516506\n",
      "Epoch 86, training loss 0.2592400312423706, test loss 0.2656216025352478, validation loss 0.3164210319519043\n",
      "Epoch 86, training AUC 0.7087867417336067, test AUC 0.6709066718006397\n",
      "Epoch 86, training MCC 0.1621304110514264, test MCC 0.13235520010608468\n",
      "Epoch 87, training loss 0.2590978741645813, test loss 0.2655746340751648, validation loss 0.31631967425346375\n",
      "Epoch 87, training AUC 0.7094100785195211, test AUC 0.6711629851199366\n",
      "Epoch 87, training MCC 0.16308184427471006, test MCC 0.1322884011144681\n",
      "Epoch 88, training loss 0.2589518129825592, test loss 0.2655194103717804, validation loss 0.3162398040294647\n",
      "Epoch 88, training AUC 0.7100937910713427, test AUC 0.6713854978307997\n",
      "Epoch 88, training MCC 0.16428298312387657, test MCC 0.13220339354357596\n",
      "Epoch 89, training loss 0.2588074803352356, test loss 0.26546260714530945, validation loss 0.31623271107673645\n",
      "Epoch 89, training AUC 0.710658202188874, test AUC 0.6715634143742887\n",
      "Epoch 89, training MCC 0.16386510362263493, test MCC 0.13185698727474957\n",
      "Epoch 90, training loss 0.25866806507110596, test loss 0.26540181040763855, validation loss 0.31613534688949585\n",
      "Epoch 90, training AUC 0.7112693817618244, test AUC 0.6719064169872343\n",
      "Epoch 90, training MCC 0.16431716179888511, test MCC 0.13174675718439677\n",
      "Epoch 91, training loss 0.2585314214229584, test loss 0.2653491497039795, validation loss 0.3159623146057129\n",
      "Epoch 91, training AUC 0.7118373843999677, test AUC 0.6722470216485924\n",
      "Epoch 91, training MCC 0.16468950241337627, test MCC 0.13279601134569818\n",
      "Epoch 92, training loss 0.25837692618370056, test loss 0.2652738392353058, validation loss 0.3159749209880829\n",
      "Epoch 92, training AUC 0.7123480772729767, test AUC 0.6725843589814923\n",
      "Epoch 92, training MCC 0.16534746340626696, test MCC 0.1332709604344427\n",
      "Epoch 93, training loss 0.2582351565361023, test loss 0.26522788405418396, validation loss 0.31588247418403625\n",
      "Epoch 93, training AUC 0.7129199440275845, test AUC 0.6728605246649288\n",
      "Epoch 93, training MCC 0.16594438942496095, test MCC 0.13469844250113963\n",
      "Epoch 94, training loss 0.25809723138809204, test loss 0.2651796042919159, validation loss 0.3157932758331299\n",
      "Epoch 94, training AUC 0.7134182351944425, test AUC 0.6730860945252262\n",
      "Epoch 94, training MCC 0.1667773723612359, test MCC 0.1339436209516894\n",
      "Epoch 95, training loss 0.2579592168331146, test loss 0.26516035199165344, validation loss 0.3157039284706116\n",
      "Epoch 95, training AUC 0.7140541338716995, test AUC 0.6731598769161066\n",
      "Epoch 95, training MCC 0.1671349169731729, test MCC 0.1343559466163993\n",
      "Epoch 96, training loss 0.2578180134296417, test loss 0.26512566208839417, validation loss 0.31569337844848633\n",
      "Epoch 96, training AUC 0.7146023241308795, test AUC 0.6732304015321211\n",
      "Epoch 96, training MCC 0.16791459423137384, test MCC 0.13276061026411706\n",
      "Epoch 97, training loss 0.2576819658279419, test loss 0.2650717794895172, validation loss 0.31553927063941956\n",
      "Epoch 97, training AUC 0.7151594678991912, test AUC 0.6734944532609237\n",
      "Epoch 97, training MCC 0.16819739735151648, test MCC 0.13472680351242516\n",
      "Epoch 98, training loss 0.25754836201667786, test loss 0.2650304138660431, validation loss 0.3154698312282562\n",
      "Epoch 98, training AUC 0.7157298255406779, test AUC 0.6737278188522788\n",
      "Epoch 98, training MCC 0.16798653347100997, test MCC 0.13542466562130684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, training loss 0.2574099898338318, test loss 0.2649745047092438, validation loss 0.3154333233833313\n",
      "Epoch 99, training AUC 0.7163020913531315, test AUC 0.6740140349144808\n",
      "Epoch 99, training MCC 0.16975852971311653, test MCC 0.1355381762647056\n",
      "Epoch 100, training loss 0.2572742998600006, test loss 0.26491761207580566, validation loss 0.31538861989974976\n",
      "Epoch 100, training AUC 0.7168326584309671, test AUC 0.674285481123478\n",
      "Epoch 100, training MCC 0.1697424003385206, test MCC 0.1363347031477813\n",
      "Epoch 101, training loss 0.2571403384208679, test loss 0.26488813757896423, validation loss 0.31524956226348877\n",
      "Epoch 101, training AUC 0.7173830547493649, test AUC 0.6744214287373882\n",
      "Epoch 101, training MCC 0.1705303163559622, test MCC 0.1363358010748125\n",
      "Epoch 102, training loss 0.2570018172264099, test loss 0.2648421823978424, validation loss 0.3152160346508026\n",
      "Epoch 102, training AUC 0.7179356318345822, test AUC 0.6745844130166085\n",
      "Epoch 102, training MCC 0.17086518597049982, test MCC 0.1362632237360153\n",
      "Epoch 103, training loss 0.25687307119369507, test loss 0.26481616497039795, validation loss 0.3151933252811432\n",
      "Epoch 103, training AUC 0.7184070456124466, test AUC 0.6747238667987762\n",
      "Epoch 103, training MCC 0.17126035628846056, test MCC 0.13566668397263573\n",
      "Epoch 104, training loss 0.2567445635795593, test loss 0.2648022472858429, validation loss 0.31509968638420105\n",
      "Epoch 104, training AUC 0.7189736065838654, test AUC 0.6748403537458182\n",
      "Epoch 104, training MCC 0.17164516332228844, test MCC 0.1355422414805135\n",
      "Epoch 105, training loss 0.25660696625709534, test loss 0.26474833488464355, validation loss 0.3150614798069\n",
      "Epoch 105, training AUC 0.7195384673440398, test AUC 0.6751401645694112\n",
      "Epoch 105, training MCC 0.1717510146887692, test MCC 0.1357518247886206\n",
      "Epoch 106, training loss 0.2564707398414612, test loss 0.2647015154361725, validation loss 0.31508269906044006\n",
      "Epoch 106, training AUC 0.7199918982264454, test AUC 0.6752926016830831\n",
      "Epoch 106, training MCC 0.17346379592488595, test MCC 0.1339829310361219\n",
      "Epoch 107, training loss 0.2563477158546448, test loss 0.2646598815917969, validation loss 0.3149355947971344\n",
      "Epoch 107, training AUC 0.7204647873942326, test AUC 0.6755387977484706\n",
      "Epoch 107, training MCC 0.1734112945101481, test MCC 0.13509974948316453\n",
      "Epoch 108, training loss 0.25621679425239563, test loss 0.26462799310684204, validation loss 0.31490907073020935\n",
      "Epoch 108, training AUC 0.7209909901281633, test AUC 0.6756901361990644\n",
      "Epoch 108, training MCC 0.17402393459897234, test MCC 0.13512588965083042\n",
      "Epoch 109, training loss 0.25609052181243896, test loss 0.2645909786224365, validation loss 0.31496256589889526\n",
      "Epoch 109, training AUC 0.7214606587305189, test AUC 0.6758282238175787\n",
      "Epoch 109, training MCC 0.17460309970244303, test MCC 0.13458296777712483\n",
      "Epoch 110, training loss 0.255969762802124, test loss 0.26458391547203064, validation loss 0.3148273825645447\n",
      "Epoch 110, training AUC 0.7220169369367424, test AUC 0.6759023979057304\n",
      "Epoch 110, training MCC 0.17564911128579375, test MCC 0.13562715677966078\n",
      "Epoch 111, training loss 0.2558346390724182, test loss 0.26456913352012634, validation loss 0.3148207366466522\n",
      "Epoch 111, training AUC 0.722542701269096, test AUC 0.6758990923629045\n",
      "Epoch 111, training MCC 0.17574263933528944, test MCC 0.13539629526868155\n",
      "Epoch 112, training loss 0.25571370124816895, test loss 0.264536052942276, validation loss 0.3147672712802887\n",
      "Epoch 112, training AUC 0.7229999625447678, test AUC 0.6761029182478498\n",
      "Epoch 112, training MCC 0.1766528960288054, test MCC 0.13485781240501393\n",
      "Epoch 113, training loss 0.2555815279483795, test loss 0.2644871175289154, validation loss 0.3147413432598114\n",
      "Epoch 113, training AUC 0.7235022695824824, test AUC 0.6763225266667503\n",
      "Epoch 113, training MCC 0.1774633671485715, test MCC 0.13643462329287823\n",
      "Epoch 114, training loss 0.25545284152030945, test loss 0.2644728720188141, validation loss 0.3146720230579376\n",
      "Epoch 114, training AUC 0.7240152472021717, test AUC 0.6763706958775256\n",
      "Epoch 114, training MCC 0.1778855075783077, test MCC 0.1357085300438064\n",
      "Epoch 115, training loss 0.25532373785972595, test loss 0.2644190788269043, validation loss 0.31471869349479675\n",
      "Epoch 115, training AUC 0.7243985956581114, test AUC 0.676592558944134\n",
      "Epoch 115, training MCC 0.1779346209391863, test MCC 0.13580741825713552\n",
      "Epoch 116, training loss 0.2552019953727722, test loss 0.2643906772136688, validation loss 0.3147048354148865\n",
      "Epoch 116, training AUC 0.7249026647329334, test AUC 0.6767198127893401\n",
      "Epoch 116, training MCC 0.17790172700420945, test MCC 0.13560846452907807\n",
      "Epoch 117, training loss 0.2550841271877289, test loss 0.2643842399120331, validation loss 0.3145681917667389\n",
      "Epoch 117, training AUC 0.7254016472253553, test AUC 0.6768342170533298\n",
      "Epoch 117, training MCC 0.17837372917783686, test MCC 0.13576874024271995\n",
      "Epoch 118, training loss 0.2549459636211395, test loss 0.2643481492996216, validation loss 0.31460481882095337\n",
      "Epoch 118, training AUC 0.725984108684742, test AUC 0.6769274792182625\n",
      "Epoch 118, training MCC 0.17970492135776867, test MCC 0.13429719838151954\n",
      "Epoch 119, training loss 0.2548215687274933, test loss 0.26432543992996216, validation loss 0.31452929973602295\n",
      "Epoch 119, training AUC 0.7264828157710449, test AUC 0.6770572456581601\n",
      "Epoch 119, training MCC 0.17869723301598361, test MCC 0.13439750378087786\n",
      "Epoch 120, training loss 0.2546946704387665, test loss 0.26429712772369385, validation loss 0.3145729601383209\n",
      "Epoch 120, training AUC 0.7268972373438918, test AUC 0.6771808786920047\n",
      "Epoch 120, training MCC 0.1794607371565993, test MCC 0.1343958539577811\n",
      "Epoch 121, training loss 0.2545737624168396, test loss 0.264261394739151, validation loss 0.314599871635437\n",
      "Epoch 121, training AUC 0.7272962614664776, test AUC 0.6773495664656386\n",
      "Epoch 121, training MCC 0.18039307259526574, test MCC 0.13363851536754617\n",
      "Epoch 122, training loss 0.25445789098739624, test loss 0.2642498314380646, validation loss 0.3143683671951294\n",
      "Epoch 122, training AUC 0.7279066906982674, test AUC 0.6774851128286856\n",
      "Epoch 122, training MCC 0.18025395071222075, test MCC 0.1347445812946251\n",
      "Epoch 123, training loss 0.25432950258255005, test loss 0.26422959566116333, validation loss 0.3143840432167053\n",
      "Epoch 123, training AUC 0.7284039898410439, test AUC 0.6775549209253013\n",
      "Epoch 123, training MCC 0.18012467518198272, test MCC 0.1355966715707259\n",
      "Epoch 124, training loss 0.25419920682907104, test loss 0.2642098665237427, validation loss 0.3144243061542511\n",
      "Epoch 124, training AUC 0.7288182905724303, test AUC 0.6776001571833383\n",
      "Epoch 124, training MCC 0.18123288777536806, test MCC 0.13562211595476933\n",
      "Epoch 125, training loss 0.2540794014930725, test loss 0.26420682668685913, validation loss 0.3143622577190399\n",
      "Epoch 125, training AUC 0.7292161203317453, test AUC 0.6776762419898863\n",
      "Epoch 125, training MCC 0.18163712836014434, test MCC 0.13612107301728696\n",
      "Epoch 126, training loss 0.2539600133895874, test loss 0.264187216758728, validation loss 0.3143186867237091\n",
      "Epoch 126, training AUC 0.7296807866596963, test AUC 0.6778208642653165\n",
      "Epoch 126, training MCC 0.18179953586353215, test MCC 0.13694696835840509\n",
      "Epoch 127, training loss 0.25383564829826355, test loss 0.2641485631465912, validation loss 0.31420013308525085\n",
      "Epoch 127, training AUC 0.7302203775033265, test AUC 0.678001274296313\n",
      "Epoch 127, training MCC 0.18150480423851167, test MCC 0.13745922078493863\n",
      "Epoch 128, training loss 0.25371068716049194, test loss 0.26411136984825134, validation loss 0.3141879439353943\n",
      "Epoch 128, training AUC 0.7306972881625032, test AUC 0.6781449316589531\n",
      "Epoch 128, training MCC 0.18121277438820318, test MCC 0.13696091900337928\n",
      "Epoch 129, training loss 0.25358593463897705, test loss 0.2640892565250397, validation loss 0.31429988145828247\n",
      "Epoch 129, training AUC 0.731137848024249, test AUC 0.6782706760366259\n",
      "Epoch 129, training MCC 0.181508084264856, test MCC 0.137316851474874\n",
      "Epoch 130, training loss 0.25345736742019653, test loss 0.2640589475631714, validation loss 0.3143220841884613\n",
      "Epoch 130, training AUC 0.7315920545402137, test AUC 0.6783638713264145\n",
      "Epoch 130, training MCC 0.18198489206806978, test MCC 0.1352220830782849\n",
      "Epoch 131, training loss 0.2533389925956726, test loss 0.26401957869529724, validation loss 0.3143139183521271\n",
      "Epoch 131, training AUC 0.7320567264886977, test AUC 0.6785946861087103\n",
      "Epoch 131, training MCC 0.1829733482052764, test MCC 0.13570679209153008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132, training loss 0.2532188594341278, test loss 0.2639741897583008, validation loss 0.31421801447868347\n",
      "Epoch 132, training AUC 0.7325461034901555, test AUC 0.6788426113742467\n",
      "Epoch 132, training MCC 0.1830814819329133, test MCC 0.1363778025464288\n",
      "Epoch 133, training loss 0.25309741497039795, test loss 0.26393240690231323, validation loss 0.3142216205596924\n",
      "Epoch 133, training AUC 0.732936921634504, test AUC 0.679096574509916\n",
      "Epoch 133, training MCC 0.18332766846536758, test MCC 0.1363347031477813\n",
      "Epoch 134, training loss 0.252969890832901, test loss 0.2638949751853943, validation loss 0.31427186727523804\n",
      "Epoch 134, training AUC 0.7334066661140559, test AUC 0.6793077566606879\n",
      "Epoch 134, training MCC 0.18448391180807766, test MCC 0.13594961637734188\n",
      "EARLY-STOPPING !\n",
      "Best epoch found: nÂº 128\n",
      "Exiting. . .\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "train_X, train_y, train_mask = training_set[:]\n",
    "test_X, test_y, test_mask = test_set[:]\n",
    "\n",
    "criterion= nn.BCELoss(reduction='none')\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=LR_DECAY)\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "net.apply(weight_reset)\n",
    "losses=[]\n",
    "training_plot=[]\n",
    "test_plot=[]\n",
    "auc_train_plot=[]\n",
    "auc_test_plot=[]\n",
    "mcc_train_plot=[]\n",
    "mcc_test_plot=[]\n",
    "\n",
    "last_score=np.inf\n",
    "max_es_rounds = 5\n",
    "es_rounds = max_es_rounds\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "   \n",
    "    for i, data in enumerate(trainloader,0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, mask = data\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #scheduler.step()     \n",
    "        # forward + backward + optimize\n",
    "        outputs, hidden = net(inputs)\n",
    "        loss = criterion(torch.squeeze(outputs), labels)\n",
    "        loss=loss*mask\n",
    "        loss=torch.sum(loss)/torch.sum(mask)\n",
    "   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "# print statistics\n",
    "    with torch.no_grad():\n",
    "        test_loss=0\n",
    "        train_loss=0\n",
    "        net.eval()\n",
    "        inputs, labels, mask = training_set[:]\n",
    "\n",
    "        outputs, hidden = net(inputs) \n",
    "\n",
    "        loss = criterion(torch.squeeze(outputs), labels)\n",
    "        loss=loss*mask\n",
    "        loss=torch.sum(loss)/torch.sum(mask)\n",
    "        training_plot.append(loss.cpu().numpy())\n",
    "        auc_train_plot.append(roc_auc_score(labels.cpu()[mask.cpu()>0], outputs.cpu().squeeze()[mask.cpu()>0]))\n",
    "        mcc_train_plot.append(mcc(labels.cpu()[mask.cpu()>0], outputs.cpu().squeeze()[mask.cpu()>0]>.1))\n",
    " \n",
    "\n",
    "        inputs, labels, mask = test_set[:]\n",
    "        outputs, hidden = net(inputs)\n",
    "        loss = criterion(torch.squeeze(outputs), labels)\n",
    "        loss=loss*mask\n",
    "        loss=torch.sum(loss)/torch.sum(mask)       \n",
    "        test_plot.append(loss.cpu().numpy())\n",
    "        fpr, tpr, _ = roc_curve(labels.cpu()[mask.cpu()>0], outputs.cpu()[mask.cpu()>0].squeeze())\n",
    "        #labels, outputs= get_labels_preds_and_posprob_without_padding( outputs.flatten(),labels.flatten() )\n",
    "        auc_test_plot.append(roc_auc_score(labels.cpu()[mask.cpu()>0], outputs.cpu()[mask.cpu()>0].squeeze()))\n",
    "        mcc_test_plot.append(mcc(labels.cpu()[mask.cpu()>0], outputs.cpu().squeeze()[mask.cpu()>0]>.1))\n",
    "        \n",
    "        inputs, labels, mask = val_set[:]\n",
    "\n",
    "        outputs, hidden = net(inputs) \n",
    "\n",
    "        valloss = criterion(torch.squeeze(outputs), labels)\n",
    "        valloss=valloss*mask\n",
    "        valloss=torch.sum(valloss)/torch.sum(mask)\n",
    "        \n",
    "        print(\"Epoch {}, training loss {}, test loss {}, validation loss {}\".format(epoch, training_plot[-1], test_plot[-1], valloss))\n",
    "        print(\"Epoch {}, training AUC {}, test AUC {}\".format(epoch, auc_train_plot[-1], auc_test_plot[-1]))\n",
    "        print(\"Epoch {}, training MCC {}, test MCC {}\".format(epoch, mcc_train_plot[-1], mcc_test_plot[-1]))\n",
    "\n",
    "        \n",
    "    if EARLY_STOPPING:\n",
    "        if last_score > valloss:\n",
    "            last_score = valloss\n",
    "            best_epoch = epoch\n",
    "            es_rounds = max_es_rounds\n",
    "            best_model = copy.deepcopy(net)\n",
    "            rnn_fpr, rnn_tpr = fpr, tpr\n",
    "        else:\n",
    "            if es_rounds > 0:\n",
    "                es_rounds -=1\n",
    "            else:\n",
    "                print('EARLY-STOPPING !')\n",
    "                print('Best epoch found: nÂº {}'.format(best_epoch))\n",
    "                print('Exiting. . .')\n",
    "                break\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19ece8",
   "metadata": {},
   "source": [
    "## GNN Finetuning (ProteinSolver)\n",
    "\n",
    "With this model, we want to preserve the structural, biological context as much as possible. To do this, we preserve the GNN of ProteinSolver and adds a linear layer at the end. This prevents us from having to take the embeddings out of the structure they come from and force it into sequences, for example. This way we use the information contained within the pretrained GNN to our advantage and finetune it into predicting epitopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "043d98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PS_model_for_finetuning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5d1aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ce215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "embed_x.0.weight \t torch.Size([21, 128])\n",
      "embed_x.2.weight \t torch.Size([128, 128])\n",
      "embed_x.2.bias \t torch.Size([128])\n",
      "embed_x.3.weight \t torch.Size([128])\n",
      "embed_x.3.bias \t torch.Size([128])\n",
      "embed_adj.0.weight \t torch.Size([128, 2])\n",
      "embed_adj.0.bias \t torch.Size([128])\n",
      "embed_adj.2.weight \t torch.Size([128, 128])\n",
      "embed_adj.2.bias \t torch.Size([128])\n",
      "embed_adj.3.weight \t torch.Size([128])\n",
      "embed_adj.3.bias \t torch.Size([128])\n",
      "graph_conv_0.gnn.nn.0.weight \t torch.Size([256, 384])\n",
      "graph_conv_0.gnn.nn.0.bias \t torch.Size([256])\n",
      "graph_conv_0.gnn.nn.2.weight \t torch.Size([128, 256])\n",
      "graph_conv_0.gnn.nn.2.bias \t torch.Size([128])\n",
      "graph_conv_0.x_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv_0.x_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv_0.edge_attr_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv_0.edge_attr_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv.0.gnn.nn.0.weight \t torch.Size([256, 384])\n",
      "graph_conv.0.gnn.nn.0.bias \t torch.Size([256])\n",
      "graph_conv.0.gnn.nn.2.weight \t torch.Size([128, 256])\n",
      "graph_conv.0.gnn.nn.2.bias \t torch.Size([128])\n",
      "graph_conv.0.x_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv.0.x_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv.0.edge_attr_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv.0.edge_attr_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv.1.gnn.nn.0.weight \t torch.Size([256, 384])\n",
      "graph_conv.1.gnn.nn.0.bias \t torch.Size([256])\n",
      "graph_conv.1.gnn.nn.2.weight \t torch.Size([128, 256])\n",
      "graph_conv.1.gnn.nn.2.bias \t torch.Size([128])\n",
      "graph_conv.1.x_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv.1.x_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv.1.edge_attr_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv.1.edge_attr_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv.2.gnn.nn.0.weight \t torch.Size([256, 384])\n",
      "graph_conv.2.gnn.nn.0.bias \t torch.Size([256])\n",
      "graph_conv.2.gnn.nn.2.weight \t torch.Size([128, 256])\n",
      "graph_conv.2.gnn.nn.2.bias \t torch.Size([128])\n",
      "graph_conv.2.x_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv.2.x_postprocess.0.bias \t torch.Size([128])\n",
      "graph_conv.2.edge_attr_postprocess.0.weight \t torch.Size([128])\n",
      "graph_conv.2.edge_attr_postprocess.0.bias \t torch.Size([128])\n",
      "linear_out.weight \t torch.Size([20, 128])\n",
      "linear_out.bias \t torch.Size([20])\n",
      "linear_pred_out.weight \t torch.Size([1, 128])\n",
      "linear_pred_out.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "\n",
    "#Define model\n",
    "gnn = Net(\n",
    "    x_input_size=num_features + 1,\n",
    "    adj_input_size=adj_input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=num_features\n",
    ")\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "state_dict = torch.load(STATE_FILE, map_location=device)\n",
    "\n",
    "state_dict['linear_pred_out.weight'] = torch.empty(1, 128)\n",
    "state_dict['linear_pred_out.bias'] = torch.empty(1)\n",
    "torch.nn.init.kaiming_uniform_(state_dict['linear_pred_out.weight'], a=math.sqrt(3))\n",
    "\n",
    "fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(state_dict['linear_pred_out.weight'])\n",
    "bound = 1 / math.sqrt(fan_in)\n",
    "torch.nn.init.uniform_(state_dict['linear_pred_out.bias'], -bound, bound)\n",
    "\n",
    "# Model weight shapes\n",
    "for param_tensor in state_dict:\n",
    "    print(param_tensor, \"\\t\", state_dict[param_tensor].size())\n",
    "\n",
    "# Set up network\n",
    "gnn.load_state_dict(state_dict)\n",
    "gnn.train()\n",
    "gnn = gnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ee2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datapoints: 216 \n",
      "Validation datapoints: 24 \n",
      "Test datapoints: 117\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/postapr2018_antigens.test.txt\", \"r\") as infile:\n",
    "    test_names = set([l.strip() for l in infile.readlines()])\n",
    "with open(\"data/preapr2018_antigens.train.txt\", \"r\") as infile:\n",
    "    train_names = set([l.strip() for l in infile.readlines()])\n",
    "with open(\"data/preapr2018_antigens.validation.txt\", \"r\") as infile:\n",
    "    val_names = set([l.strip() for l in infile.readlines()])\n",
    "\n",
    "PDB_FILES = glob.glob(INPUT_DIR + \"*.pdb\")\n",
    "#print(\"Found %s PDB files in %s\" % (len(PDB_FILES), INPUT_DIR))\n",
    "\n",
    "# Match PDBs with FASTA\n",
    "pdb_fasta_path_dict = {}\n",
    "for pdb_path in PDB_FILES:\n",
    "    # Get PDB name\n",
    "    bn_pdb_path = os.path.basename(pdb_path)\n",
    "    filename_pdb, filename_chain = bn_pdb_path.split(\".\")[0].split(\"_\")[0:2]\n",
    "    pdb_name = filename_pdb + \"_\" + filename_chain\n",
    "\n",
    "    # Get fasta file from PDB name\n",
    "    fasta_path = INPUT_DIR + pdb_name + \".fasta\"\n",
    "\n",
    "    # Create matching PDB + FASTA path dict\n",
    "    #if os.path.isfile(fasta_path):\n",
    "    #    pdb_fasta_path_dict[pdb_name] = {\"fasta_path\":fasta_path, \n",
    "    #                                \"pdb_path\":pdb_path}\n",
    "    #else:\n",
    "    #    print(\"PDB %s does not have matching %s\" % (pdb_path, fasta_path))\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "val_data = []\n",
    "\n",
    "def seq_to_y(seq):\n",
    "    return torch.Tensor([1 if res.isupper() else 0 for res in seq])\n",
    "\n",
    "if os.path.isfile('data/train_data.pt') and os.path.isfile('data/test_data.pt') and os.path.isfile('data/val_data.pt'):\n",
    "    train_data = torch.load('data/train_data.pt', map_location=device)\n",
    "    test_data = torch.load('data/test_data.pt', map_location=device)\n",
    "    val_data = torch.load('data/val_data.pt', map_location=device)\n",
    "else:\n",
    "    for i, (pdb, paths) in enumerate(pdb_fasta_path_dict.items()):\n",
    "        pdb_path, fasta_path = paths[\"pdb_path\"], paths[\"fasta_path\"]\n",
    "        f_fasta = os.path.basename(fasta_path)\n",
    "        f_pdb = os.path.basename(pdb_path)\n",
    "\n",
    "        # Load PDB\n",
    "        structure_all = PDB.load(pdb_path)\n",
    "\n",
    "        # Check that PDB id matches between PDB filename and data\n",
    "        f_id, f_chain = f_pdb.split(\".\")[0].split(\"_\")[0:2]\n",
    "        s_id, s_chain = structure_all.id.split(\"_\")[0:2]\n",
    "\n",
    "        print(\"Reading in PDB %s, chain %s, FASTA %s (%s of %s)\" % (\n",
    "            f_id, f_chain, f_fasta, i+1, len(PDB_FILES))\n",
    "            )\n",
    "    \n",
    "        pdb_name = f_id + \"_\" + f_chain\n",
    "\n",
    "        chain = \"A\" # Hard-coded output alphafold\n",
    "        structure = PDB.Structure(pdb_name, structure_all[0].extract(chain))\n",
    "    \n",
    "        # Seq PDB\n",
    "        seq_pdb = \"\".join([res_dict[res.resname] for res in structure_all.residues])\n",
    "\n",
    "        # Read fasta\n",
    "        records = list(SeqIO.parse(fasta_path, \"fasta\"))\n",
    "        seq_fasta_epitopes = str(records[0].seq)\n",
    "\n",
    "\n",
    "        # Check sanity\n",
    "        try:\n",
    "            assert(f_id.upper() == s_id.upper())\n",
    "            assert len(list(structure.chains)) == 1\n",
    "            assert len(records) == 1\n",
    "            assert(seq_pdb.upper() == seq_fasta_epitopes.upper())\n",
    "        except AssertionError as error:\n",
    "            print(\"Error %s for PDB %s\" % (error, pdb_name))\n",
    "            continue\n",
    "\n",
    "        # Run proteinsolver\n",
    "        #Extract sequences and adjacency matrix\n",
    "        protein_data = proteinsolver.utils.extract_seq_and_adj(structure, chain)\n",
    "\n",
    "        #Preprocess data\n",
    "        data1 = proteinsolver.datasets.protein.row_to_data(protein_data)\n",
    "        data2 = proteinsolver.datasets.protein.transform_edge_attr(data1)\n",
    "\n",
    "        if pdb_name in test_names:\n",
    "            test_data.append((data2,seq_to_y(seq_fasta_epitopes)))\n",
    "        elif pdb_name in train_names:\n",
    "            train_data.append((data2, seq_to_y(seq_fasta_epitopes)))\n",
    "        elif pdb_name in val_names:\n",
    "            val_data.append((data2, seq_to_y(seq_fasta_epitopes)))\n",
    "\n",
    "    torch.save(train_data, 'data/train_data.pt')\n",
    "    torch.save(test_data, 'data/test_data.pt')\n",
    "    torch.save(val_data, 'data/val_data.pt')\n",
    "\n",
    "print(\"Training datapoints:\", len(train_data), \"\\nValidation datapoints:\", \n",
    "      len(val_data), \"\\nTest datapoints:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e4b9051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.3837987184524536\n",
      "Epoch 0: Training AUC 0.6074913061032897\n",
      "Epoch 0: Test AUC 0.6943233473585159\n",
      "Epoch 0: Validation AUC 0.6970753663825422\n",
      "Validation loss 9.038689389824867\n",
      "\n",
      "Epoch 1: Training loss: 0.33668598532676697\n",
      "Epoch 1: Training AUC 0.6884999335765406\n",
      "Epoch 1: Test AUC 0.7092052833045095\n",
      "Epoch 1: Validation AUC 0.7150683969618277\n",
      "Validation loss 8.84957928955555\n",
      "\n",
      "Epoch 2: Training loss: 0.3305877447128296\n",
      "Epoch 2: Training AUC 0.7050842661788224\n",
      "Epoch 2: Test AUC 0.7146067600146866\n",
      "Epoch 2: Validation AUC 0.7231714196624306\n",
      "Validation loss 8.764408573508263\n",
      "\n",
      "Epoch 3: Training loss: 0.3266954720020294\n",
      "Epoch 3: Training AUC 0.7182415658787062\n",
      "Epoch 3: Test AUC 0.7169577365905019\n",
      "Epoch 3: Validation AUC 0.7293404757200901\n",
      "Validation loss 8.706224113702774\n",
      "\n",
      "Epoch 4: Training loss: 0.3233238160610199\n",
      "Epoch 4: Training AUC 0.725727607228698\n",
      "Epoch 4: Test AUC 0.7167676965387871\n",
      "Epoch 4: Validation AUC 0.7289530873248421\n",
      "Validation loss 8.719024166464806\n",
      "\n",
      "Epoch 5: Training loss: 0.321651816368103\n",
      "Epoch 5: Training AUC 0.7289216577955546\n",
      "Epoch 5: Test AUC 0.7201068106869385\n",
      "Epoch 5: Validation AUC 0.7245019887127756\n",
      "Validation loss 8.729327127337456\n",
      "\n",
      "Epoch 6: Training loss: 0.318050354719162\n",
      "Epoch 6: Training AUC 0.7376209193047256\n",
      "Epoch 6: Test AUC 0.7216765518319816\n",
      "Epoch 6: Validation AUC 0.7289144079919834\n",
      "Validation loss 8.674221783876419\n",
      "\n",
      "Epoch 7: Training loss: 0.31535956263542175\n",
      "Epoch 7: Training AUC 0.7433562798339299\n",
      "Epoch 7: Test AUC 0.7214026121354769\n",
      "Epoch 7: Validation AUC 0.7290899526564967\n",
      "Validation loss 8.64002051949501\n",
      "\n",
      "Epoch 8: Training loss: 0.3128092885017395\n",
      "Epoch 8: Training AUC 0.7512606265450985\n",
      "Epoch 8: Test AUC 0.7207724954226831\n",
      "Epoch 8: Validation AUC 0.7344473377907793\n",
      "Validation loss 8.62991039454937\n",
      "\n",
      "Epoch 9: Training loss: 0.3102269470691681\n",
      "Epoch 9: Training AUC 0.7575726172306614\n",
      "Epoch 9: Test AUC 0.7180526068924656\n",
      "Epoch 9: Validation AUC 0.7359659479054843\n",
      "Validation loss 8.605923399329185\n",
      "\n",
      "Epoch 10: Training loss: 0.30578991770744324\n",
      "Epoch 10: Training AUC 0.764197848653299\n",
      "Epoch 10: Test AUC 0.7203730024203453\n",
      "Epoch 10: Validation AUC 0.7365514934983017\n",
      "Validation loss 8.605177417397499\n",
      "\n",
      "Epoch 11: Training loss: 0.302365243434906\n",
      "Epoch 11: Training AUC 0.7732038704249509\n",
      "Epoch 11: Test AUC 0.7152906443431577\n",
      "Epoch 11: Validation AUC 0.7339867561964291\n",
      "Validation loss 8.67212063074112\n",
      "\n",
      "Epoch 12: Training loss: 0.2992299497127533\n",
      "Epoch 12: Training AUC 0.7763709424332192\n",
      "Epoch 12: Test AUC 0.7128961511558624\n",
      "Epoch 12: Validation AUC 0.7277593836061516\n",
      "Validation loss 8.813633278012276\n",
      "\n",
      "Epoch 13: Training loss: 0.29480743408203125\n",
      "Epoch 13: Training AUC 0.7861579344604029\n",
      "Epoch 13: Test AUC 0.703541245225879\n",
      "Epoch 13: Validation AUC 0.7207756812918182\n",
      "Validation loss 8.813250124454498\n",
      "\n",
      "Epoch 14: Training loss: 0.2885335385799408\n",
      "Epoch 14: Training AUC 0.795305933706892\n",
      "Epoch 14: Test AUC 0.7009756949741379\n",
      "Epoch 14: Validation AUC 0.722194915274409\n",
      "Validation loss 8.840661346912384\n",
      "\n",
      "Epoch 15: Training loss: 0.2846086323261261\n",
      "Epoch 15: Training AUC 0.798683570554675\n",
      "Epoch 15: Test AUC 0.6928864871243565\n",
      "Epoch 15: Validation AUC 0.7084363790431806\n",
      "Validation loss 9.190133348107338\n",
      "\n",
      "Epoch 16: Training loss: 0.28095772862434387\n",
      "Epoch 16: Training AUC 0.8060507348206207\n",
      "Epoch 16: Test AUC 0.6983741467878072\n",
      "Epoch 16: Validation AUC 0.7214266842171659\n",
      "Validation loss 9.065979346632957\n",
      "\n",
      "EARLY-STOPPING !\n",
      "Best epoch found: nÂº 10\n",
      "Exiting. . .\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-4\n",
    "\n",
    "criterion= nn.BCELoss()\n",
    "optimizer = optim.Adam(gnn.parameters(), lr=LR)\n",
    "\n",
    "last_score = np.inf\n",
    "max_es_rounds = 5\n",
    "es_rounds = max_es_rounds\n",
    "best_epoch = 0\n",
    "\n",
    "auc_test = []\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):  # loop over the dataset multiple times\n",
    "    gnn.train()\n",
    "\n",
    "    losses = []\n",
    "    true_vec = []\n",
    "    pred_vec = []\n",
    "\n",
    "    for i, data in enumerate(train_data):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        #inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #scheduler.step()     \n",
    "        # forward + backward + optimize\n",
    "        outputs = gnn(inputs.x, inputs.edge_index, inputs.edge_attr)\n",
    "\n",
    "        #print(labels, outputs.shape)\n",
    "        outputs = torch.flatten(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss)\n",
    "\n",
    "        true_vec.extend(list(labels.detach().cpu().numpy()))\n",
    "        pred_vec.extend(list(outputs.detach().cpu().numpy()))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch {}: Training loss: {}\".format(epoch, sum(losses)/len(losses)))\n",
    "    print(\"Epoch {}: Training AUC {}\".format(epoch, roc_auc_score(true_vec, pred_vec)))\n",
    "\n",
    "    gnn.eval()\n",
    "\n",
    "    true_vec = []\n",
    "    pred_vec = []\n",
    "    \n",
    "    for i, data in enumerate(test_data):\n",
    "        inputs, labels = data\n",
    "        outputs = gnn(inputs.x, inputs.edge_index, inputs.edge_attr)\n",
    "        outputs = torch.flatten(outputs)\n",
    "\n",
    "        true_vec.extend(list(labels.detach().cpu().numpy()))\n",
    "        pred_vec.extend(list(outputs.detach().cpu().numpy()))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(true_vec, pred_vec)\n",
    "    auc_test.append(roc_auc_score(true_vec, pred_vec))\n",
    "    print(\"Epoch {}: Test AUC {}\".format(epoch, auc_test[epoch]))\n",
    "\n",
    "    true_vec = []\n",
    "    pred_vec = []\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, data in enumerate(val_data):\n",
    "        inputs, labels = data\n",
    "        outputs = gnn(inputs.x, inputs.edge_index, inputs.edge_attr)\n",
    "        outputs = torch.flatten(outputs)\n",
    "        val_loss += criterion(outputs, labels).detach().cpu().numpy()\n",
    "\n",
    "        true_vec.extend(list(labels.detach().cpu().numpy()))\n",
    "        pred_vec.extend(list(outputs.detach().cpu().numpy()))\n",
    "\n",
    "    print(\"Epoch {}: Validation AUC {}\".format(epoch, roc_auc_score(true_vec, pred_vec)))\n",
    "    print(\"Validation loss {}\".format(val_loss))\n",
    "    print()\n",
    "\n",
    "    if EARLY_STOPPING:\n",
    "        if last_score > val_loss:\n",
    "            last_score = val_loss\n",
    "            best_epoch = epoch\n",
    "            es_rounds = max_es_rounds\n",
    "            best_model = copy.deepcopy(gnn)\n",
    "            gnn_fpr, gnn_tpr = fpr, tpr\n",
    "        else:\n",
    "            if es_rounds > 0:\n",
    "                es_rounds -=1\n",
    "            else:\n",
    "                print('EARLY-STOPPING !')\n",
    "                print('Best epoch found: nÂº {}'.format(best_epoch))\n",
    "                print('Exiting. . .')\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9feab0",
   "metadata": {},
   "source": [
    "## Discotope\n",
    "Discotope is our structural reference method. Developed in 2012, it is still the \"state-of-the-art\" in terms of predicting epitopes directly from structure. We submitted both the AF2 and solved PDB files to the Discotope 2.0 web server (https://services.healthtech.dtu.dk/service.php?DiscoTope-2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f73d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average: 0.6497387876176202\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "epitope_dict = SeqIO.to_dict(SeqIO.parse(\"data/antigens_before_clustering.fasta\", \"fasta\"))\n",
    "\n",
    "all_true = []\n",
    "all_pred = []\n",
    "\n",
    "def tryfloat(x):\n",
    "    try:\n",
    "        x = float(x.split()[5])\n",
    "        return x\n",
    "    except:\n",
    "        return -1000\n",
    "\n",
    "performance_dict = dict()\n",
    "\n",
    "metric = roc_auc_score\n",
    "\n",
    "disco_glob = 'data/discotope_af2/*.txt' if SOLVED else 'data/discotope_solved/*.txt'\n",
    "\n",
    "for filename in glob.glob(disco_glob):\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        pdb_id = os.path.splitext(filename)[0].rsplit(\"/\", 1)[-1]\n",
    "        reference_entry = epitope_dict.get(pdb_id, None)\n",
    "        \n",
    "        if reference_entry is None:\n",
    "            raise ValueError('The reference for {} does not exist!'.format(pdb_id))\n",
    "\n",
    "        reference = str(reference_entry.seq)\n",
    "        reference_length = len(reference)\n",
    "        \n",
    "        y_true = [1 if reference[idx].isupper() else 0 for idx in range(reference_length) ]\n",
    "        all_true.extend(y_true)\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        \n",
    "        y_pred = [tryfloat(line) for line in lines[:reference_length]]\n",
    "        all_pred.extend(y_pred)\n",
    "        performance_dict[pdb_id] = metric(y_true, y_pred)\n",
    "\n",
    "pdb_ids, performances = zip(*sorted(performance_dict.items()))\n",
    "\n",
    "print(\"Micro-average:\", metric(all_true, all_pred))\n",
    "\n",
    "discotope_fpr, discotope_tpr, _ = roc_curve(all_true, all_pred)\n",
    "\n",
    "plt.hist(performances, bins=20)\n",
    "plt.show()\n",
    "\n",
    "#print(pdb_ids)\n",
    "#print(performances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d49e75",
   "metadata": {},
   "source": [
    "# BepiPred3\n",
    "BepiPred3 is the, yet unpublished, state-of-the-art tool for predicting epitopes directly from sequence using ESM embedding instead of the structural embeddings we use in our methods. It uses a specific FFNN architecture, which we have tried to implement to the best of our ability to use with our dataset and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "990506cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dicts = list()\n",
    "\n",
    "embedding_type = \"data/esm_embeddings/\"\n",
    "SEQ_KEY_NAME = \"seq_pdb\"\n",
    "\n",
    "for pt in glob.glob(embedding_type+'*.pt'):\n",
    "    pt_obj = torch.load(pt)\n",
    "    embedding_dicts.append(pt_obj)\n",
    "\n",
    "fasta = {}\n",
    "with open(\"data/antigens_before_clustering.fasta\", \"r\") as file_one:\n",
    "    for line in file_one:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\">\"):\n",
    "            active_sequence_name = line[1:]\n",
    "            if active_sequence_name not in fasta:\n",
    "                fasta[active_sequence_name] = []\n",
    "            continue\n",
    "        sequence = line\n",
    "        fasta[active_sequence_name].append(sequence)\n",
    "\n",
    "for embed_dict in embedding_dicts:\n",
    "    embed_dict[SEQ_KEY_NAME] = fasta[embed_dict['label']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4ee137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dims: torch.Size([216, 927, 1280]) torch.Size([216, 927])\n",
      "Test dims: torch.Size([117, 927, 1280]) torch.Size([117, 927])\n",
      "Validation dims: torch.Size([24, 927, 1280]) torch.Size([24, 927])\n"
     ]
    }
   ],
   "source": [
    "def create_bepipred_datasets(list_of_dicts):\n",
    "    n_seqs = len(list_of_dicts)\n",
    "    seq_max_length = max([len(embed_dict[SEQ_KEY_NAME]) for embed_dict in list_of_dicts])\n",
    "    embedding_dim = 1280\n",
    "\n",
    "    with open(\"data/postapr2018_antigens.test.txt\", \"r\") as infile:\n",
    "        test_names = set([l.strip() for l in infile.readlines()])\n",
    "    with open(\"data/preapr2018_antigens.train.txt\", \"r\") as infile:\n",
    "        train_names = set([l.strip() for l in infile.readlines()])\n",
    "    with open(\"data/preapr2018_antigens.validation.txt\", \"r\") as infile:\n",
    "        val_names = set([l.strip() for l in infile.readlines()])\n",
    "\n",
    "    X = torch.zeros(size=(n_seqs, seq_max_length, embedding_dim))\n",
    "    y = torch.zeros(size=(n_seqs, seq_max_length))\n",
    "    mask = torch.zeros(size=(n_seqs, seq_max_length))\n",
    "    test_idx = list()\n",
    "    train_idx = list()\n",
    "    val_idx = list()\n",
    "    for i, embed_dict in enumerate(list_of_dicts):\n",
    "        seq = embed_dict[SEQ_KEY_NAME]\n",
    "        pdb_id = embed_dict['label']\n",
    "        embedding = list(embed_dict['representations'].values())[0]\n",
    "        \n",
    "        if pdb_id in test_names:\n",
    "            test_idx.append(i)\n",
    "        elif pdb_id in train_names:\n",
    "            train_idx.append(i)\n",
    "        elif pdb_id in val_names:\n",
    "            val_idx.append(i)\n",
    "        y_ = torch.Tensor([1 if letter.isupper() else 0 for letter in seq])\n",
    "\n",
    "        X[i, 0:embedding.shape[0]] = embedding\n",
    "        y[i, 0:len(y_)] = y_\n",
    "        mask[i, 0:len(y_)] = torch.ones((1,len(y_)))\n",
    "\n",
    "    test_idx = np.asarray(test_idx)\n",
    "    train_idx = np.asarray(train_idx)\n",
    "    val_idx = np.asarray(val_idx)\n",
    "\n",
    "\n",
    "    random_indices = np.random.choice(len(train_idx), len(train_idx), replace=False)\n",
    "\n",
    "    inputs_train = X[train_idx, :, :]\n",
    "    inputs_test = X[test_idx, :, :]\n",
    "    inputs_val = X[val_idx, :, :]\n",
    "    targets_train = y[train_idx]\n",
    "    targets_test = y[test_idx]\n",
    "    targets_val = y[val_idx]\n",
    "    masks_train = mask[train_idx]\n",
    "    masks_test = mask[test_idx]\n",
    "    masks_val = mask[val_idx]\n",
    "\n",
    "    print(\"Training dims:\", inputs_train.shape, targets_train.shape)\n",
    "    print(\"Test dims:\", inputs_test.shape, targets_test.shape)\n",
    "    print(\"Validation dims:\", inputs_val.shape, targets_val.shape)\n",
    "    \n",
    "    training_set = EpitopeDataset(inputs_train.to(device), targets_train.to(device), masks_train.to(device))\n",
    "    validation_set = EpitopeDataset(inputs_val.to(device), targets_val.to(device), masks_val.to(device))\n",
    "    test_set = EpitopeDataset(inputs_test.to(device), targets_test.to(device), masks_test.to(device))\n",
    "\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "training_set, val_set, test_set = create_bepipred_datasets(embedding_dicts)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(training_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e8ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BepiPred3Net(\n",
      "  (ff_model): Sequential(\n",
      "    (0): Linear(in_features=1280, out_features=180, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.7, inplace=False)\n",
      "    (3): Linear(in_features=180, out_features=90, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.7, inplace=False)\n",
      "    (6): Linear(in_features=90, out_features=45, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.7, inplace=False)\n",
      "    (9): Linear(in_features=45, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BepiPred3Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_size = 1280,\n",
    "                 fc1_size = 180,\n",
    "                 fc2_size = 90,\n",
    "                 fc3_size = 45,\n",
    "                 fc1_dropout = 0.7,\n",
    "                 fc2_dropout = 0.7,\n",
    "                 fc3_dropout = 0.7,\n",
    "                 num_of_classes = 1):\n",
    "        super(BepiPred3Net, self).__init__()\n",
    "\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.fc1_size = fc1_size\n",
    "        self.fc2_size = fc2_size\n",
    "        self.fc3_size = fc3_size\n",
    "        self.fc1_dropout = fc1_dropout\n",
    "        self.fc2_dropout = fc2_dropout\n",
    "        self.fc3_dropout = fc3_dropout\n",
    "\n",
    "        self.ff_model = nn.Sequential(nn.Linear(embedding_size, fc1_size),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout(fc1_dropout),\n",
    "                                      nn.Linear(fc1_size, fc2_size),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout(fc2_dropout),\n",
    "                                      nn.Linear(fc2_size, fc3_size),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout(fc3_dropout),\n",
    "                                      nn.Linear(fc3_size, num_of_classes),\n",
    "                                      nn.Sigmoid()\n",
    "                                )\n",
    "    def forward(self, x):\n",
    "        output = x\n",
    "        batch_size = output.size(0)\n",
    "        seq_len = output.size(1)\n",
    "        #convert dim (N, L, esm_embedding) --> (N*L, esm_embedding)\n",
    "        output = torch.reshape(output, (batch_size*seq_len, self.embedding_size))\n",
    "        output = self.ff_model(output)\n",
    "        output = output.view(output.shape[0])\n",
    "        return output\n",
    "\n",
    "net = BepiPred3Net()\n",
    "net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a6ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_EPOCHS = 200\n",
    "LR = 1e-4\n",
    "LR_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6a53bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 0, training loss 0.6321365237236023, test loss 0.6322209239006042, validation loss 0.6355239152908325\n",
      "Epoch 0, training AUC 0.5575499895266988, test AUC 0.5249801973145388\n",
      "Epoch 0, training MCC 0.0, test MCC 0.0\n",
      "Epoch 1, training loss 0.5877063870429993, test loss 0.5877530574798584, validation loss 0.5937902927398682\n",
      "Epoch 1, training AUC 0.5619209881427661, test AUC 0.5417960191175784\n",
      "Epoch 1, training MCC 0.0, test MCC 0.0\n",
      "Epoch 2, training loss 0.48361724615097046, test loss 0.48351210355758667, validation loss 0.4972628653049469\n",
      "Epoch 2, training AUC 0.5562200027936297, test AUC 0.5428037606606623\n",
      "Epoch 2, training MCC 0.0, test MCC 0.0\n",
      "Epoch 3, training loss 0.3444792926311493, test loss 0.3444431722164154, validation loss 0.37532973289489746\n",
      "Epoch 3, training AUC 0.5610688085438937, test AUC 0.549536845682128\n",
      "Epoch 3, training MCC 0.0, test MCC 0.0\n",
      "Epoch 4, training loss 0.28639358282089233, test loss 0.28667470812797546, validation loss 0.33451321721076965\n",
      "Epoch 4, training AUC 0.575813329912452, test AUC 0.5622559057248486\n",
      "Epoch 4, training MCC 0.05547524700641183, test MCC 0.05969075349495772\n",
      "Epoch 5, training loss 0.27804017066955566, test loss 0.2786903381347656, validation loss 0.3317720293998718\n",
      "Epoch 5, training AUC 0.5976615333888777, test AUC 0.5807273459112613\n",
      "Epoch 5, training MCC 0.07788019483797627, test MCC 0.06012148025479642\n",
      "Epoch 6, training loss 0.2758731245994568, test loss 0.2769075036048889, validation loss 0.3307172656059265\n",
      "Epoch 6, training AUC 0.6203264171775, test AUC 0.5997071040662839\n",
      "Epoch 6, training MCC 0.09278669421932735, test MCC 0.07690269866213775\n",
      "Epoch 7, training loss 0.27509376406669617, test loss 0.27656635642051697, validation loss 0.329424649477005\n",
      "Epoch 7, training AUC 0.6426374153443745, test AUC 0.6188298030645477\n",
      "Epoch 7, training MCC 0.11254660559412354, test MCC 0.09293013915908897\n",
      "Epoch 8, training loss 0.2735961079597473, test loss 0.27542844414711, validation loss 0.32835206389427185\n",
      "Epoch 8, training AUC 0.6593694752267925, test AUC 0.633662910601919\n",
      "Epoch 8, training MCC 0.12306324412434658, test MCC 0.10319086520168017\n",
      "Epoch 9, training loss 0.27154815196990967, test loss 0.27369067072868347, validation loss 0.32773521542549133\n",
      "Epoch 9, training AUC 0.6707932114392596, test AUC 0.6434863055755375\n",
      "Epoch 9, training MCC 0.13390054791433617, test MCC 0.11402720878801538\n",
      "Epoch 10, training loss 0.2704576253890991, test loss 0.2729931175708771, validation loss 0.32674965262413025\n",
      "Epoch 10, training AUC 0.6815728064627676, test AUC 0.6524756815226804\n",
      "Epoch 10, training MCC 0.13975022541473198, test MCC 0.11917962008012453\n",
      "Epoch 11, training loss 0.26912155747413635, test loss 0.2720308303833008, validation loss 0.3258516788482666\n",
      "Epoch 11, training AUC 0.6906731688814827, test AUC 0.6592422996520046\n",
      "Epoch 11, training MCC 0.14813103225695198, test MCC 0.12506124820915587\n",
      "Epoch 12, training loss 0.26750290393829346, test loss 0.2707158923149109, validation loss 0.3253597915172577\n",
      "Epoch 12, training AUC 0.6973563985845519, test AUC 0.6633434656182274\n",
      "Epoch 12, training MCC 0.16108613928422916, test MCC 0.1323370441751763\n",
      "Epoch 13, training loss 0.26676204800605774, test loss 0.27037158608436584, validation loss 0.3244413733482361\n",
      "Epoch 13, training AUC 0.7026455730984382, test AUC 0.6668085247694834\n",
      "Epoch 13, training MCC 0.16299545856228284, test MCC 0.13573855166330476\n",
      "Epoch 14, training loss 0.26568737626075745, test loss 0.26963868737220764, validation loss 0.3238454759120941\n",
      "Epoch 14, training AUC 0.7070405123749861, test AUC 0.6697609859429212\n",
      "Epoch 14, training MCC 0.16701086383526045, test MCC 0.13744579578514934\n",
      "Epoch 15, training loss 0.26453080773353577, test loss 0.2687970697879791, validation loss 0.3233526051044464\n",
      "Epoch 15, training AUC 0.7115882261703395, test AUC 0.6724341478547524\n",
      "Epoch 15, training MCC 0.17365184671058653, test MCC 0.1373682576520003\n",
      "Epoch 16, training loss 0.26407328248023987, test loss 0.2688264548778534, validation loss 0.32224324345588684\n",
      "Epoch 16, training AUC 0.7157450993392119, test AUC 0.6746554439729981\n",
      "Epoch 16, training MCC 0.17223834450589412, test MCC 0.1371653069517406\n",
      "Epoch 17, training loss 0.2631966769695282, test loss 0.26831966638565063, validation loss 0.3216401934623718\n",
      "Epoch 17, training AUC 0.7193774671751315, test AUC 0.6759957460529908\n",
      "Epoch 17, training MCC 0.17703443021257703, test MCC 0.13963585314538324\n",
      "Epoch 18, training loss 0.2620593011379242, test loss 0.2673720419406891, validation loss 0.3217827379703522\n",
      "Epoch 18, training AUC 0.7213203533642611, test AUC 0.6766809392235634\n",
      "Epoch 18, training MCC 0.1838574060701557, test MCC 0.13875142584963204\n",
      "Epoch 19, training loss 0.2611723840236664, test loss 0.2668015658855438, validation loss 0.3213118612766266\n",
      "Epoch 19, training AUC 0.724336283618572, test AUC 0.678106277825792\n",
      "Epoch 19, training MCC 0.19072098781640168, test MCC 0.14014893328735287\n",
      "Epoch 20, training loss 0.2606496512889862, test loss 0.2667909860610962, validation loss 0.3202631175518036\n",
      "Epoch 20, training AUC 0.7269965830756263, test AUC 0.6789822371210701\n",
      "Epoch 20, training MCC 0.18617204395926457, test MCC 0.13969174667488357\n",
      "Epoch 21, training loss 0.2598119378089905, test loss 0.26635730266571045, validation loss 0.3196915090084076\n",
      "Epoch 21, training AUC 0.7295834305966575, test AUC 0.6795373963511698\n",
      "Epoch 21, training MCC 0.18961187920139416, test MCC 0.14292893435519555\n",
      "Epoch 22, training loss 0.25910821557044983, test loss 0.265969455242157, validation loss 0.3195130228996277\n",
      "Epoch 22, training AUC 0.7314999677268994, test AUC 0.6800142734485655\n",
      "Epoch 22, training MCC 0.19331401653014024, test MCC 0.14400042697328866\n",
      "Epoch 23, training loss 0.2586369216442108, test loss 0.2658182680606842, validation loss 0.31924521923065186\n",
      "Epoch 23, training AUC 0.7328598528854703, test AUC 0.6806554532208752\n",
      "Epoch 23, training MCC 0.19025593562207718, test MCC 0.1433194215985017\n",
      "Epoch 24, training loss 0.257975310087204, test loss 0.2655318081378937, validation loss 0.3184700310230255\n",
      "Epoch 24, training AUC 0.7346947152398526, test AUC 0.6815117703310373\n",
      "Epoch 24, training MCC 0.1916856293957317, test MCC 0.14439460802985665\n",
      "Epoch 25, training loss 0.2572188377380371, test loss 0.265064001083374, validation loss 0.3182060122489929\n",
      "Epoch 25, training AUC 0.7368799728649658, test AUC 0.6823633966275362\n",
      "Epoch 25, training MCC 0.1968860509982341, test MCC 0.1429146455106672\n",
      "Epoch 26, training loss 0.2568066120147705, test loss 0.265095055103302, validation loss 0.31739386916160583\n",
      "Epoch 26, training AUC 0.7382363845341187, test AUC 0.6828029573946484\n",
      "Epoch 26, training MCC 0.19490397348258628, test MCC 0.145493986342311\n",
      "Epoch 27, training loss 0.25602808594703674, test loss 0.2644939720630646, validation loss 0.3177467882633209\n",
      "Epoch 27, training AUC 0.739265846986114, test AUC 0.6830187539303477\n",
      "Epoch 27, training MCC 0.19878295316749733, test MCC 0.14128259891743158\n",
      "Epoch 28, training loss 0.2556074857711792, test loss 0.26457276940345764, validation loss 0.31695640087127686\n",
      "Epoch 28, training AUC 0.7415784293564308, test AUC 0.683098641066505\n",
      "Epoch 28, training MCC 0.20034344300754867, test MCC 0.14260028132849345\n",
      "Epoch 29, training loss 0.2551015317440033, test loss 0.26440751552581787, validation loss 0.3165997564792633\n",
      "Epoch 29, training AUC 0.7431449787045872, test AUC 0.6831860182187762\n",
      "Epoch 29, training MCC 0.2020808330965776, test MCC 0.14294319930331228\n",
      "Epoch 30, training loss 0.25454631447792053, test loss 0.26411935687065125, validation loss 0.3165018558502197\n",
      "Epoch 30, training AUC 0.7448065768869698, test AUC 0.6833883346361884\n",
      "Epoch 30, training MCC 0.20576145625727746, test MCC 0.14387965599439032\n",
      "Epoch 31, training loss 0.25403520464897156, test loss 0.2640196979045868, validation loss 0.3159474730491638\n",
      "Epoch 31, training AUC 0.74692799930809, test AUC 0.6837054852292296\n",
      "Epoch 31, training MCC 0.2084269000576481, test MCC 0.14437867678688937\n",
      "Epoch 32, training loss 0.2536500096321106, test loss 0.26404038071632385, validation loss 0.315310001373291\n",
      "Epoch 32, training AUC 0.7487197015892643, test AUC 0.6838283921900838\n",
      "Epoch 32, training MCC 0.20784896068296943, test MCC 0.1444643974829691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, training loss 0.25302854180336, test loss 0.2636743485927582, validation loss 0.31551897525787354\n",
      "Epoch 33, training AUC 0.7502985374226444, test AUC 0.6841229963060463\n",
      "Epoch 33, training MCC 0.21226165181560067, test MCC 0.14468573770238466\n",
      "Epoch 34, training loss 0.25273433327674866, test loss 0.2637575566768646, validation loss 0.314926415681839\n",
      "Epoch 34, training AUC 0.75107440985471, test AUC 0.6847574025816404\n",
      "Epoch 34, training MCC 0.20886647770855168, test MCC 0.144164122122722\n",
      "Epoch 35, training loss 0.25202739238739014, test loss 0.26330721378326416, validation loss 0.31484007835388184\n",
      "Epoch 35, training AUC 0.7527962966847376, test AUC 0.6850846226606311\n",
      "Epoch 35, training MCC 0.21301154610428386, test MCC 0.147591875105908\n",
      "Epoch 36, training loss 0.2516356110572815, test loss 0.2631711959838867, validation loss 0.3150950074195862\n",
      "Epoch 36, training AUC 0.7540455809941631, test AUC 0.684736499322383\n",
      "Epoch 36, training MCC 0.21590706417264982, test MCC 0.14575806644645334\n",
      "Epoch 37, training loss 0.25138717889785767, test loss 0.26326489448547363, validation loss 0.3143922686576843\n",
      "Epoch 37, training AUC 0.7547072582462044, test AUC 0.6855197219002874\n",
      "Epoch 37, training MCC 0.21338989905332004, test MCC 0.14636264488835427\n",
      "Epoch 38, training loss 0.2508309483528137, test loss 0.26290610432624817, validation loss 0.3143381178379059\n",
      "Epoch 38, training AUC 0.7562161605972442, test AUC 0.6857926202552658\n",
      "Epoch 38, training MCC 0.2166521061833089, test MCC 0.1457030745107767\n",
      "Epoch 39, training loss 0.25056716799736023, test loss 0.2633305788040161, validation loss 0.31303122639656067\n",
      "Epoch 39, training AUC 0.7581708920597539, test AUC 0.6849966436320647\n",
      "Epoch 39, training MCC 0.21649732721486672, test MCC 0.14730006766403184\n",
      "Epoch 40, training loss 0.2499309778213501, test loss 0.2628839910030365, validation loss 0.313304603099823\n",
      "Epoch 40, training AUC 0.7594012042599054, test AUC 0.6852831558556183\n",
      "Epoch 40, training MCC 0.21980449051391693, test MCC 0.145561224872793\n",
      "Epoch 41, training loss 0.24961480498313904, test loss 0.26288682222366333, validation loss 0.3131045699119568\n",
      "Epoch 41, training AUC 0.7603133184128416, test AUC 0.68529304382332\n",
      "Epoch 41, training MCC 0.221046973971787, test MCC 0.14731055592633172\n",
      "Epoch 42, training loss 0.24932372570037842, test loss 0.262849897146225, validation loss 0.31288668513298035\n",
      "Epoch 42, training AUC 0.7616567297890747, test AUC 0.6857491896261136\n",
      "Epoch 42, training MCC 0.2213461638276826, test MCC 0.14775076712101115\n",
      "Epoch 43, training loss 0.2489692121744156, test loss 0.26260697841644287, validation loss 0.3132537007331848\n",
      "Epoch 43, training AUC 0.7625355479042865, test AUC 0.6862205160865675\n",
      "Epoch 43, training MCC 0.22266434695734952, test MCC 0.14850530334187934\n",
      "Epoch 44, training loss 0.2485644817352295, test loss 0.2625257670879364, validation loss 0.31269776821136475\n",
      "Epoch 44, training AUC 0.7639280799290158, test AUC 0.6864364177117788\n",
      "Epoch 44, training MCC 0.22488029697021975, test MCC 0.15024067554372078\n",
      "Epoch 45, training loss 0.24826128780841827, test loss 0.26242339611053467, validation loss 0.3128938376903534\n",
      "Epoch 45, training AUC 0.764447984855676, test AUC 0.6865781834632062\n",
      "Epoch 45, training MCC 0.22609771148965538, test MCC 0.14843566701497943\n",
      "Epoch 46, training loss 0.2478771060705185, test loss 0.26225560903549194, validation loss 0.3128047585487366\n",
      "Epoch 46, training AUC 0.7657019819820547, test AUC 0.6868546070936262\n",
      "Epoch 46, training MCC 0.2267416383726233, test MCC 0.15072634986919983\n",
      "Epoch 47, training loss 0.2475900948047638, test loss 0.2622425854206085, validation loss 0.31261157989501953\n",
      "Epoch 47, training AUC 0.7665509494462954, test AUC 0.6869206033070409\n",
      "Epoch 47, training MCC 0.2282368000842782, test MCC 0.1492880311167244\n",
      "Epoch 48, training loss 0.24731911718845367, test loss 0.262430340051651, validation loss 0.3119197487831116\n",
      "Epoch 48, training AUC 0.7682790806885297, test AUC 0.6867493456171635\n",
      "Epoch 48, training MCC 0.22790371791704614, test MCC 0.14962204770601537\n",
      "Epoch 49, training loss 0.24692121148109436, test loss 0.26228389143943787, validation loss 0.3120863139629364\n",
      "Epoch 49, training AUC 0.7690531461192232, test AUC 0.6866191206048509\n",
      "Epoch 49, training MCC 0.22960544680251754, test MCC 0.1501173235191687\n",
      "Epoch 50, training loss 0.24660809338092804, test loss 0.26234346628189087, validation loss 0.3118725121021271\n",
      "Epoch 50, training AUC 0.7700345726855988, test AUC 0.685996589444091\n",
      "Epoch 50, training MCC 0.2299046142881001, test MCC 0.1497534370652967\n",
      "Epoch 51, training loss 0.24634940922260284, test loss 0.2624358832836151, validation loss 0.3115411102771759\n",
      "Epoch 51, training AUC 0.7712148621417013, test AUC 0.6857746690559308\n",
      "Epoch 51, training MCC 0.2304584241395399, test MCC 0.14704191929392313\n",
      "Epoch 52, training loss 0.24603703618049622, test loss 0.26218459010124207, validation loss 0.31211617588996887\n",
      "Epoch 52, training AUC 0.7716985483534571, test AUC 0.6859772147595506\n",
      "Epoch 52, training MCC 0.2326035681642378, test MCC 0.14613269583168748\n",
      "Epoch 53, training loss 0.2457655668258667, test loss 0.26215583086013794, validation loss 0.31207430362701416\n",
      "Epoch 53, training AUC 0.7722064759242108, test AUC 0.6861121879070786\n",
      "Epoch 53, training MCC 0.2322089576884388, test MCC 0.1480850278443646\n",
      "Epoch 54, training loss 0.24546131491661072, test loss 0.2621456980705261, validation loss 0.3119833171367645\n",
      "Epoch 54, training AUC 0.7732121888138488, test AUC 0.6859716832297929\n",
      "Epoch 54, training MCC 0.23345220637423625, test MCC 0.14832942745769273\n",
      "Epoch 55, training loss 0.24517738819122314, test loss 0.2621740996837616, validation loss 0.3113296926021576\n",
      "Epoch 55, training AUC 0.7742629896195273, test AUC 0.6861692801727656\n",
      "Epoch 55, training MCC 0.23246333006625758, test MCC 0.14843980718656116\n",
      "Epoch 56, training loss 0.24492165446281433, test loss 0.2621527314186096, validation loss 0.3112289011478424\n",
      "Epoch 56, training AUC 0.7753761024647453, test AUC 0.686300708937668\n",
      "Epoch 56, training MCC 0.2338005417389162, test MCC 0.14996278849011335\n",
      "Epoch 57, training loss 0.24467812478542328, test loss 0.2620372772216797, validation loss 0.31163159012794495\n",
      "Epoch 57, training AUC 0.7757204697137915, test AUC 0.6864998249017662\n",
      "Epoch 57, training MCC 0.23516358555378758, test MCC 0.148531569036649\n",
      "Epoch 58, training loss 0.24436664581298828, test loss 0.2621493935585022, validation loss 0.3111065626144409\n",
      "Epoch 58, training AUC 0.7767418442187433, test AUC 0.6859486495195231\n",
      "Epoch 58, training MCC 0.23697647260459118, test MCC 0.14838916962872997\n",
      "Epoch 59, training loss 0.2440716028213501, test loss 0.26225152611732483, validation loss 0.3109249174594879\n",
      "Epoch 59, training AUC 0.7781100477662125, test AUC 0.6853186570034249\n",
      "Epoch 59, training MCC 0.2395525181229151, test MCC 0.1477274425803293\n",
      "Epoch 60, training loss 0.2439393550157547, test loss 0.26239070296287537, validation loss 0.3105473816394806\n",
      "Epoch 60, training AUC 0.7784311488187426, test AUC 0.6854860168277732\n",
      "Epoch 60, training MCC 0.23726570385592902, test MCC 0.14816172424848592\n",
      "Epoch 61, training loss 0.2436242550611496, test loss 0.2620587944984436, validation loss 0.3114740252494812\n",
      "Epoch 61, training AUC 0.7786073665808546, test AUC 0.6855739098740118\n",
      "Epoch 61, training MCC 0.2393237131871139, test MCC 0.14827088872989844\n",
      "Epoch 62, training loss 0.2433023899793625, test loss 0.26196911931037903, validation loss 0.31140175461769104\n",
      "Epoch 62, training AUC 0.7797664750581988, test AUC 0.6858173353977244\n",
      "Epoch 62, training MCC 0.24409296491616186, test MCC 0.1462609760807121\n",
      "Epoch 63, training loss 0.2431042343378067, test loss 0.26218917965888977, validation loss 0.3101915419101715\n",
      "Epoch 63, training AUC 0.7808976860198031, test AUC 0.6858473623373254\n",
      "Epoch 63, training MCC 0.23959286530539112, test MCC 0.1492006080057775\n",
      "Epoch 64, training loss 0.24286460876464844, test loss 0.26208797097206116, validation loss 0.31057503819465637\n",
      "Epoch 64, training AUC 0.7813189140581605, test AUC 0.6856959665651795\n",
      "Epoch 64, training MCC 0.24185018231824323, test MCC 0.14887819667744004\n",
      "Epoch 65, training loss 0.24262331426143646, test loss 0.2621907591819763, validation loss 0.3101999759674072\n",
      "Epoch 65, training AUC 0.7823403560095087, test AUC 0.6854513468424691\n",
      "Epoch 65, training MCC 0.24341739932582354, test MCC 0.14727588262085728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, training loss 0.24239253997802734, test loss 0.2621367275714874, validation loss 0.31047606468200684\n",
      "Epoch 66, training AUC 0.7835192487631513, test AUC 0.6853641703156292\n",
      "Epoch 66, training MCC 0.24503505552583485, test MCC 0.14746202402626266\n",
      "Epoch 67, training loss 0.2421872615814209, test loss 0.2621438503265381, validation loss 0.31033018231391907\n",
      "Epoch 67, training AUC 0.7841189146741709, test AUC 0.6854834182507542\n",
      "Epoch 67, training MCC 0.24667722363643155, test MCC 0.14834793792880308\n",
      "Epoch 68, training loss 0.24195612967014313, test loss 0.2621440291404724, validation loss 0.3101995885372162\n",
      "Epoch 68, training AUC 0.78457686446514, test AUC 0.685584667218584\n",
      "Epoch 68, training MCC 0.24567528517052578, test MCC 0.1496931554657503\n",
      "Epoch 69, training loss 0.24170753359794617, test loss 0.26204875111579895, validation loss 0.31058868765830994\n",
      "Epoch 69, training AUC 0.7846089942422586, test AUC 0.6857723953010391\n",
      "Epoch 69, training MCC 0.24775636916396385, test MCC 0.1478167957394971\n",
      "EARLY-STOPPING !\n",
      "Best epoch found: nÂº 63\n",
      "Exiting. . .\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "\n",
    "train_X, train_y, train_mask = training_set[:]\n",
    "test_X, test_y, test_mask = test_set[:]\n",
    "\n",
    "criterion= nn.BCELoss(reduction='none')\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=LR_DECAY)\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "net.apply(weight_reset)\n",
    "losses=[]\n",
    "training_plot=[]\n",
    "test_plot=[]\n",
    "auc_train_plot=[]\n",
    "auc_test_plot=[]\n",
    "mcc_train_plot=[]\n",
    "mcc_test_plot=[]\n",
    "\n",
    "last_score=np.inf\n",
    "max_es_rounds = 5\n",
    "es_rounds = max_es_rounds\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "   \n",
    "    for i, data in enumerate(trainloader,0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, mask = data\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        #scheduler.step()     \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(torch.squeeze(outputs), torch.flatten(labels))\n",
    "        mask = torch.flatten(mask)\n",
    "        loss=loss*mask\n",
    "        loss=torch.sum(loss)/torch.sum(mask)\n",
    "   \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "# print statistics\n",
    "    with torch.no_grad():\n",
    "        test_loss=0\n",
    "        train_loss=0\n",
    "        net.eval()\n",
    "        inputs, labels, mask = training_set[:]\n",
    "\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        loss = criterion(torch.squeeze(outputs), torch.flatten(labels))\n",
    "        labels = torch.flatten(labels)\n",
    "        mask = torch.flatten(mask)\n",
    "        loss=loss*mask\n",
    "        loss=torch.sum(loss)/torch.sum(mask)\n",
    "        training_plot.append(loss)\n",
    "        auc_train_plot.append(roc_auc_score(labels.cpu()[mask.cpu()>0], outputs.cpu().squeeze()[mask.cpu()>0]))\n",
    "        mcc_train_plot.append(mcc(labels.cpu()[mask.cpu()>0], outputs.cpu().squeeze()[mask.cpu()>0]>.1))\n",
    " \n",
    "\n",
    "        inputs, labels, mask = test_set[:]\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(torch.squeeze(outputs), torch.flatten(labels))\n",
    "        labels = torch.flatten(labels)\n",
    "        mask = torch.flatten(mask)\n",
    "        loss=loss*mask\n",
    "        loss=torch.sum(loss)/torch.sum(mask)       \n",
    "        test_plot.append(loss)\n",
    "        fpr, tpr, _ = roc_curve(labels.cpu()[mask.cpu()>0], outputs.cpu()[mask.cpu()>0].squeeze())\n",
    "        #labels, outputs= get_labels_preds_and_posprob_without_padding( outputs.flatten(),labels.flatten() )\n",
    "        auc_test_plot.append(roc_auc_score(labels.cpu()[mask.cpu()>0], outputs.cpu()[mask.cpu()>0].squeeze()))\n",
    "        mcc_test_plot.append(mcc(labels.cpu()[mask.cpu()>0], outputs.cpu().squeeze()[mask.cpu()>0]>.1))\n",
    "        \n",
    "        inputs, labels, mask = val_set[:]\n",
    "        outputs = net(inputs)\n",
    "        valloss = criterion(torch.squeeze(outputs), torch.flatten(labels))\n",
    "        labels = torch.flatten(labels)\n",
    "        mask = torch.flatten(mask)\n",
    "        valloss=valloss*mask\n",
    "        valloss=torch.sum(valloss)/torch.sum(mask)   \n",
    "        \n",
    "        print(\"Epoch {}, training loss {}, test loss {}, validation loss {}\".format(epoch, training_plot[-1], test_plot[-1], valloss))\n",
    "        print(\"Epoch {}, training AUC {}, test AUC {}\".format(epoch, auc_train_plot[-1], auc_test_plot[-1]))\n",
    "        print(\"Epoch {}, training MCC {}, test MCC {}\".format(epoch, mcc_train_plot[-1], mcc_test_plot[-1]))\n",
    "\n",
    "        \n",
    "    if EARLY_STOPPING:\n",
    "        if last_score > valloss:\n",
    "            last_score = valloss\n",
    "            best_epoch = epoch\n",
    "            es_rounds = max_es_rounds\n",
    "            best_model = copy.deepcopy(net)\n",
    "            bepipred_fpr, bepipred_tpr = fpr, tpr\n",
    "        else:\n",
    "            if es_rounds > 0:\n",
    "                es_rounds -=1\n",
    "            else:\n",
    "                print('EARLY-STOPPING !')\n",
    "                print('Best epoch found: nÂº {}'.format(best_epoch))\n",
    "                print('Exiting. . .')\n",
    "                break\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7142d2",
   "metadata": {},
   "source": [
    "# Overall performance comparison\n",
    "All five methods: our three own (FFN, RNN and GNN) and the two references (Discotope2 and BepiPred3) are compared in the ROC AUC plot below. Note that the GNN can only use AF2 structures in this notebook, BepiPred always uses sequence embeddings and the `SOLVED` flag can therefore only change the FFNN, RNN and the Discotope results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f013b2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    discotope_fpr,\n",
    "    discotope_tpr,\n",
    "    color=\"darkgrey\",\n",
    "    lw=lw,\n",
    "    label=\"Discotope (area = %0.4f)\" % auc(discotope_fpr, discotope_tpr),\n",
    ")\n",
    "plt.plot(\n",
    "    ffnn_fpr,\n",
    "    ffnn_tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"FFNN (area = %0.4f)\" % auc(ffnn_fpr, ffnn_tpr),\n",
    ")\n",
    "plt.plot(\n",
    "    rnn_fpr,\n",
    "    rnn_tpr,\n",
    "    color=\"darkgreen\",\n",
    "    lw=lw,\n",
    "    label=\"RNN (area = %0.4f)\" % auc(rnn_fpr, rnn_tpr),\n",
    ")\n",
    "plt.plot(\n",
    "    bepipred_fpr,\n",
    "    bepipred_tpr,\n",
    "    color=\"navy\",\n",
    "    lw=lw,\n",
    "    label=\"BepiPred3 (area = %0.4f)\" % auc(bepipred_fpr, bepipred_tpr),\n",
    ")\n",
    "plt.plot(\n",
    "    gnn_fpr,\n",
    "    gnn_tpr,\n",
    "    color=\"darkred\",\n",
    "    lw=lw,\n",
    "    label=\"GNN (area = %0.4f)\" % auc(gnn_fpr, gnn_tpr),\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"black\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "structure_type = \"solved\" if SOLVED else \"AF2\"\n",
    "plt.title(\"ROC Curves for models using {} structures\".format(structure_type))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
